{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Amber Prep Server - Integration Test\n",
        "\n",
        "This notebook tests the `amber_prep_server.py` MCP server tools for converting\n",
        "Boltz-2 mmCIF output to MD simulation input files.\n",
        "\n",
        "## Workflow Overview\n",
        "\n",
        "1. Parse Boltz-2 mmCIF complex → Separate protein/ligand\n",
        "2. Prepare protein with pdb4amber\n",
        "3. Add hydrogens to ligand (OpenBabel)\n",
        "4. Estimate net charge (RDKit)\n",
        "5. Run antechamber (GAFF2 + AM1-BCC)\n",
        "6. Validate frcmod\n",
        "7. Build system with tleap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup path\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test imports\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "# Verify key dependencies\n",
        "try:\n",
        "    import gemmi\n",
        "    print(f\"✓ gemmi available\")\n",
        "except ImportError:\n",
        "    print(\"✗ gemmi not installed: pip install gemmi\")\n",
        "\n",
        "try:\n",
        "    from rdkit import Chem\n",
        "    print(f\"✓ RDKit available\")\n",
        "except ImportError:\n",
        "    print(\"✗ RDKit not installed (install via conda)\")\n",
        "\n",
        "try:\n",
        "    from common.base import BaseToolWrapper\n",
        "    print(f\"✓ common.base available\")\n",
        "except ImportError:\n",
        "    print(\"✗ common.base not found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check AmberTools availability\n",
        "from common.base import BaseToolWrapper\n",
        "\n",
        "tools = [\n",
        "    (\"antechamber\", \"mcp-md\"),\n",
        "    (\"parmchk2\", \"mcp-md\"),\n",
        "    (\"pdb4amber\", \"mcp-md\"),\n",
        "    (\"tleap\", \"mcp-md\"),\n",
        "    (\"obabel\", \"mcp-md\")\n",
        "]\n",
        "\n",
        "for tool_name, env in tools:\n",
        "    wrapper = BaseToolWrapper(tool_name, conda_env=env)\n",
        "    status = \"✓\" if wrapper.is_available() else \"✗\"\n",
        "    print(f\"{status} {tool_name}: {wrapper.executable or 'NOT FOUND'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 1: Charge Estimation\n",
        "\n",
        "Test the `estimate_net_charge` function with sample molecules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload module to get latest changes\n",
        "import importlib\n",
        "import servers.amber_prep_server\n",
        "importlib.reload(servers.amber_prep_server)\n",
        "\n",
        "# Import the server functions (after reload)\n",
        "from servers.amber_prep_server import (\n",
        "    estimate_net_charge,\n",
        "    _estimate_charge_rdkit,\n",
        "    _estimate_physiological_charge\n",
        ")\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "# Debug: Test SMARTS patterns directly\n",
        "print(\"=== SMARTS Pattern Debug ===\")\n",
        "test_smiles = \"CC(=O)O\"  # Acetic acid\n",
        "mol = Chem.MolFromSmiles(test_smiles)\n",
        "mol_h = Chem.AddHs(mol)\n",
        "\n",
        "patterns_to_test = [\n",
        "    (\"[CX3](=O)[OX2H1]\", \"Standard COOH\"),\n",
        "    (\"[CX3](=O)[OH]\", \"Simplified\"),\n",
        "    (\"[C](=O)[O;H1]\", \"General with H1\"),\n",
        "    (\"[C](=O)O\", \"Most basic\"),\n",
        "    (\"C(=O)O\", \"Minimal\"),\n",
        "]\n",
        "\n",
        "for smarts, desc in patterns_to_test:\n",
        "    pattern = Chem.MolFromSmarts(smarts)\n",
        "    if pattern:\n",
        "        matches_no_h = mol.GetSubstructMatches(pattern)\n",
        "        matches_with_h = mol_h.GetSubstructMatches(pattern)\n",
        "        print(f\"  {desc}: without H={len(matches_no_h)}, with H={len(matches_with_h)}\")\n",
        "    else:\n",
        "        print(f\"  {desc}: INVALID SMARTS\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Test molecules with known charges at pH 7.4\n",
        "test_cases = [\n",
        "    (\"CCO\", 0, \"Ethanol - neutral\"),\n",
        "    (\"CC(=O)O\", -1, \"Acetic acid - deprotonated at pH 7.4\"),\n",
        "    (\"CCN\", +1, \"Ethylamine - protonated at pH 7.4\"),\n",
        "    (\"c1ccc(cc1)C(=O)O\", -1, \"Benzoic acid\"),\n",
        "    (\"NCCCC[C@H](N)C(=O)O\", +1, \"Lysine - free amino acid (2×NH3+, COO-)\"),\n",
        "    (\"CC(C)C[C@H](N)C(=O)O\", 0, \"Leucine - (NH3+, COO-)\"),\n",
        "]\n",
        "\n",
        "print(\"=== Charge Estimation Tests ===\")\n",
        "for smiles, expected, name in test_cases:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    mol = Chem.AddHs(mol)\n",
        "    \n",
        "    # Direct pattern test for debugging\n",
        "    carboxylic_pattern = Chem.MolFromSmarts(\"C(=O)O\")\n",
        "    carboxylic_matches = mol.GetSubstructMatches(carboxylic_pattern) if carboxylic_pattern else []\n",
        "    \n",
        "    charge_info = _estimate_charge_rdkit(mol)\n",
        "    estimated = _estimate_physiological_charge(charge_info)\n",
        "    \n",
        "    status = \"✓\" if estimated == expected else \"✗\"\n",
        "    print(f\"{status} {name}: formal={charge_info['formal_charge']}, estimated={estimated}, expected={expected}\")\n",
        "    print(f\"   Direct COOH matches: {len(carboxylic_matches)}\")\n",
        "    if charge_info['ionizable_groups']:\n",
        "        for group in charge_info['ionizable_groups']:\n",
        "            print(f\"   - {group['type']}: {group['count']} × {group['typical_charge']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 2: frcmod Validation\n",
        "\n",
        "Test the `_parse_frcmod_warnings` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from servers.amber_prep_server import _parse_frcmod_warnings\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "\n",
        "# Create a test frcmod with warnings\n",
        "test_frcmod_content = \"\"\"Remark line goes here\n",
        "MASS\n",
        "\n",
        "BOND\n",
        "c3-os  301.5   1.4340  ATTN, need revision\n",
        "ca-os  372.0   1.3730\n",
        "\n",
        "ANGLE\n",
        "c3-c3-os   67.8    108.42\n",
        "c3-os-c1   60.0    109.50   ATTN, need revision\n",
        "\n",
        "DIHE\n",
        "X -c3-os-X    3    1.150         0.0             3.0\n",
        "\n",
        "IMPROPER\n",
        "\n",
        "NONBON\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with tempfile.NamedTemporaryFile(mode='w', suffix='.frcmod', delete=False) as f:\n",
        "    f.write(test_frcmod_content)\n",
        "    test_frcmod_path = Path(f.name)\n",
        "\n",
        "validation = _parse_frcmod_warnings(test_frcmod_path)\n",
        "print(f\"Valid: {validation['valid']}\")\n",
        "print(f\"ATTN count: {validation['attn_count']}\")\n",
        "print(f\"Warnings:\")\n",
        "for w in validation['warnings']:\n",
        "    print(f\"  - {w}\")\n",
        "print(f\"Missing params: {validation['missing_params']}\")\n",
        "\n",
        "# Cleanup\n",
        "test_frcmod_path.unlink()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 3: sqm Output Parsing\n",
        "\n",
        "Test the `_parse_sqm_output` function with simulated error outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from servers.amber_prep_server import _parse_sqm_output\n",
        "import tempfile\n",
        "\n",
        "# Test case 1: Odd electron error\n",
        "sqm_odd_electrons = \"\"\"            --------------------------------------------------------\n",
        "                         AMBER SQM VERSION 19\n",
        " \n",
        "                                   By\n",
        "              Ross C. Walker, Michael F. Crowley, Scott Brozell,\n",
        "                         Tim Giese, Andreas W. Goetz,\n",
        "                        Tai-Sung Lee and David A. Case\n",
        " \n",
        "            --------------------------------------------------------\n",
        " \n",
        "\n",
        "QMMM: INFO: The number of electrons is odd (51)\n",
        "QMMM: Fatal Error!\n",
        "QMMM: Cannot properly run \"sqm\"\n",
        "\"\"\"\n",
        "\n",
        "with tempfile.NamedTemporaryFile(mode='w', suffix='.out', delete=False) as f:\n",
        "    f.write(sqm_odd_electrons)\n",
        "    test_sqm_path = Path(f.name)\n",
        "\n",
        "diag = _parse_sqm_output(test_sqm_path)\n",
        "print(\"Test 1: Odd electrons error\")\n",
        "print(f\"  Success: {diag['success']}\")\n",
        "print(f\"  Errors: {diag['errors']}\")\n",
        "print(f\"  Recommendations: {diag['recommendations']}\")\n",
        "test_sqm_path.unlink()\n",
        "\n",
        "# Test case 2: SCF convergence failure\n",
        "sqm_scf_fail = \"\"\"            --------------------------------------------------------\n",
        "                         AMBER SQM VERSION 19\n",
        " \n",
        "QMMM: No convergence in SCF after 1000 steps\n",
        "QMMM: Unable to achieve self consistency\n",
        "\"\"\"\n",
        "\n",
        "with tempfile.NamedTemporaryFile(mode='w', suffix='.out', delete=False) as f:\n",
        "    f.write(sqm_scf_fail)\n",
        "    test_sqm_path = Path(f.name)\n",
        "\n",
        "diag = _parse_sqm_output(test_sqm_path)\n",
        "print(\"\\nTest 2: SCF convergence failure\")\n",
        "print(f\"  Success: {diag['success']}\")\n",
        "print(f\"  SCF converged: {diag['scf_converged']}\")\n",
        "print(f\"  Errors: {diag['errors']}\")\n",
        "print(f\"  Recommendations: {diag['recommendations']}\")\n",
        "test_sqm_path.unlink()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 4: Server Import Check\n",
        "\n",
        "Verify all MCP tools are importable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import all tools from the server\n",
        "from servers.amber_prep_server import (\n",
        "    parse_structure,  # Unified parser (replaces parse_boltz2_complex)\n",
        "    estimate_net_charge,\n",
        "    prepare_ligand_hydrogens,\n",
        "    prepare_ligand_for_amber,  # NEW: SMILES template method\n",
        "    prepare_protein_for_amber,\n",
        "    run_antechamber_robust,\n",
        "    validate_frcmod,\n",
        "    build_complex_system,\n",
        "    build_multi_ligand_system,\n",
        "    boltz2_to_amber_complete\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    parse_structure,\n",
        "    estimate_net_charge,\n",
        "    prepare_ligand_hydrogens,\n",
        "    prepare_ligand_for_amber,\n",
        "    prepare_protein_for_amber,\n",
        "    run_antechamber_robust,\n",
        "    validate_frcmod,\n",
        "    build_complex_system,\n",
        "    build_multi_ligand_system,\n",
        "    boltz2_to_amber_complete\n",
        "]\n",
        "\n",
        "print(\"MCP Tools available:\")\n",
        "for tool in tools:\n",
        "    # Handle both FunctionTool objects and regular functions\n",
        "    tool_name = getattr(tool, 'name', None) or getattr(tool, '__name__', str(tool))\n",
        "    tool_doc = getattr(tool, 'description', None) or getattr(tool, '__doc__', '')\n",
        "    \n",
        "    print(f\"  ✓ {tool_name}\")\n",
        "    if tool_doc:\n",
        "        first_line = tool_doc.strip().split('\\n')[0]\n",
        "        print(f\"      {first_line}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The `amber_prep_server.py` provides the following MCP tools:\n",
        "\n",
        "| Tool | Description |\n",
        "|------|-------------|\n",
        "| `parse_structure` | Parse mmCIF/PDB with chain selection |\n",
        "| `estimate_net_charge` | Auto-estimate ligand charge at target pH |\n",
        "| `prepare_ligand_hydrogens` | Add hydrogens with OpenBabel (legacy) |\n",
        "| `prepare_ligand_for_amber` | **NEW: SMILES template matching (recommended)** |\n",
        "| `prepare_protein_for_amber` | pdb4amber preparation |\n",
        "| `run_antechamber_robust` | GAFF2 + AM1-BCC with error handling |\n",
        "| `validate_frcmod` | Check for missing parameters |\n",
        "| `build_complex_system` | tleap system building (single ligand) |\n",
        "| `build_multi_ligand_system` | tleap system building (multiple ligands) |\n",
        "| `boltz2_to_amber_complete` | Complete end-to-end workflow |\n",
        "\n",
        "### New Recommended Workflow (SMILES Template Matching)\n",
        "\n",
        "The new `prepare_ligand_for_amber()` function uses SMILES from PDB CCD to assign correct bond orders:\n",
        "\n",
        "```\n",
        "PDB (coordinates) + SMILES (bond orders) → SDF → antechamber -fi sdf\n",
        "```\n",
        "\n",
        "This eliminates bond order ambiguity that causes antechamber failures.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 4.5: SMILES Template Functions\n",
        "\n",
        "Test the new SMILES template matching functions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test SMILES template functions\n",
        "import importlib\n",
        "import servers.amber_prep_server as amber_module\n",
        "importlib.reload(amber_module)\n",
        "\n",
        "from servers.amber_prep_server import (\n",
        "    _fetch_smiles_from_ccd,\n",
        "    _get_ligand_smiles,\n",
        "    _assign_bond_orders_from_smiles,\n",
        "    _optimize_ligand_rdkit,\n",
        "    KNOWN_LIGAND_SMILES\n",
        ")\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "print(\"=== Test SMILES Functions ===\")\n",
        "print()\n",
        "\n",
        "# Test 1: Known ligands dictionary\n",
        "print(\"1. Known Ligands Dictionary:\")\n",
        "print(f\"   {len(KNOWN_LIGAND_SMILES)} ligands in dictionary\")\n",
        "for ligand_id in list(KNOWN_LIGAND_SMILES.keys())[:5]:\n",
        "    smiles = KNOWN_LIGAND_SMILES[ligand_id]\n",
        "    print(f\"   {ligand_id}: {smiles[:50]}...\")\n",
        "print()\n",
        "\n",
        "# Test 2: CCD API (requires network)\n",
        "print(\"2. CCD API Lookup:\")\n",
        "test_ligands = [\"ATP\", \"SAH\", \"HEM\"]\n",
        "for ligand_id in test_ligands:\n",
        "    try:\n",
        "        smiles = _fetch_smiles_from_ccd(ligand_id)\n",
        "        if smiles:\n",
        "            print(f\"   ✓ {ligand_id}: {smiles[:50]}...\")\n",
        "        else:\n",
        "            print(f\"   ⚠ {ligand_id}: Not found in CCD (using dictionary)\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ✗ {ligand_id}: Error - {e}\")\n",
        "print()\n",
        "\n",
        "# Test 3: SMILES lookup with fallback\n",
        "print(\"3. SMILES Lookup (with fallback):\")\n",
        "for ligand_id in [\"ATP\", \"NAD\", \"UNKNOWN_LIGAND\"]:\n",
        "    smiles = _get_ligand_smiles(ligand_id, fetch_from_ccd=True)\n",
        "    if smiles:\n",
        "        print(f\"   ✓ {ligand_id}: Found\")\n",
        "    else:\n",
        "        print(f\"   ✗ {ligand_id}: Not found\")\n",
        "print()\n",
        "\n",
        "# Test 4: Template matching with ethanol\n",
        "print(\"4. Template Matching Test (Ethanol):\")\n",
        "try:\n",
        "    # Create a \"PDB-like\" molecule (just coordinates, uncertain bonds)\n",
        "    smiles = \"CCO\"\n",
        "    template_mol = Chem.MolFromSmiles(smiles)\n",
        "    template_mol = Chem.AddHs(template_mol)\n",
        "    AllChem.EmbedMolecule(template_mol)\n",
        "    \n",
        "    # Simulate reading from PDB (sanitize=False to mimic real scenario)\n",
        "    pdb_block = Chem.MolToPDBBlock(template_mol)\n",
        "    pdb_mol = Chem.MolFromPDBBlock(pdb_block, removeHs=False, sanitize=False)\n",
        "    \n",
        "    print(f\"   PDB mol atoms: {pdb_mol.GetNumAtoms()}\")\n",
        "    \n",
        "    # Apply template matching\n",
        "    result_mol = _assign_bond_orders_from_smiles(pdb_mol, smiles)\n",
        "    print(f\"   Result mol atoms: {result_mol.GetNumAtoms()}\")\n",
        "    print(f\"   ✓ Template matching succeeded\")\n",
        "except Exception as e:\n",
        "    print(f\"   ✗ Template matching failed: {e}\")\n",
        "print()\n",
        "\n",
        "# Test 5: MMFF94 Optimization\n",
        "print(\"5. MMFF94 Optimization Test:\")\n",
        "try:\n",
        "    mol = Chem.MolFromSmiles(\"CCO\")\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    \n",
        "    opt_mol, converged = _optimize_ligand_rdkit(mol, max_iters=100)\n",
        "    print(f\"   Optimized: {opt_mol.GetNumAtoms()} atoms\")\n",
        "    print(f\"   Converged: {converged}\")\n",
        "    print(f\"   ✓ Optimization succeeded\")\n",
        "except Exception as e:\n",
        "    print(f\"   ✗ Optimization failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 5: Real Boltz-2 Output Processing\n",
        "\n",
        "Process an actual Boltz-2 mmCIF output file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with actual Boltz-2 output using parse_structure\n",
        "# Note: MCP tools are FunctionTool objects, need to access underlying function\n",
        "import importlib\n",
        "import servers.amber_prep_server as amber_module\n",
        "importlib.reload(amber_module)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Get the underlying function from FunctionTool or use directly\n",
        "def get_callable(tool):\n",
        "    \"\"\"Extract callable from FunctionTool or return as-is if already callable\"\"\"\n",
        "    if callable(tool):\n",
        "        return tool\n",
        "    # Try common attributes for wrapped functions\n",
        "    for attr in ['fn', 'func', '_func', 'function', '_fn']:\n",
        "        if hasattr(tool, attr):\n",
        "            fn = getattr(tool, attr)\n",
        "            if callable(fn):\n",
        "                return fn\n",
        "    raise TypeError(f\"Cannot extract callable from {type(tool)}\")\n",
        "\n",
        "# Access the parse function (now using parse_structure for all formats)\n",
        "parse_structure = get_callable(amber_module.parse_structure)\n",
        "\n",
        "# Path to real Boltz-2 output\n",
        "boltz2_cif = Path(\"boltz_results_ligand/predictions/ligand/ligand_model_0.cif\")\n",
        "\n",
        "if boltz2_cif.exists():\n",
        "    print(f\"Processing Boltz-2 output: {boltz2_cif}\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    try:\n",
        "        # parse_structure works for both Boltz-2 and PDB files\n",
        "        result = parse_structure(str(boltz2_cif))\n",
        "        \n",
        "        print(f\"\\n✓ Job ID: {result['job_id']}\")\n",
        "        print(f\"✓ Output directory: {result['output_dir']}\")\n",
        "        print(f\"✓ Protein chains: {result['num_protein_chains']}\")\n",
        "        print(f\"✓ Ligands found: {result['num_ligands']}\")\n",
        "        \n",
        "        print(f\"\\n--- Chain Information ---\")\n",
        "        for chain in result['all_chains']:\n",
        "            chain_type = \"Protein\" if chain['is_protein'] else \"Ligand/Other\"\n",
        "            print(f\"  {chain['name']}: {chain_type}\")\n",
        "        \n",
        "        print(f\"\\n--- Output Files ---\")\n",
        "        print(f\"  Protein PDB: {result['protein_pdb']}\")\n",
        "        for lig in result['ligand_files']:\n",
        "            print(f\"  Ligand: {lig}\")\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"✗ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"✗ Boltz-2 output file not found: {boltz2_cif}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NEW Workflow: SMILES Template Matching + Dimorphite-DL (Best Practice)\n",
        "# 1. Fetch SMILES from PDB CCD (source of truth)\n",
        "# 2. Apply pH 7.4 protonation using Dimorphite-DL\n",
        "# 3. Assign bond orders from protonated SMILES template\n",
        "# 4. Add hydrogens with correct geometry\n",
        "# 5. Optimize with MMFF94, output SDF\n",
        "prepare_ligand_for_amber = get_callable(amber_module.prepare_ligand_for_amber)\n",
        "\n",
        "# Manual SMILES overrides (if CCD lookup fails or for custom ligands)\n",
        "# For non-PDB ligands, provide SMILES manually here\n",
        "MANUAL_SMILES = {\n",
        "    # \"SAH\": None,  # Will be fetched from CCD\n",
        "    # For custom ligands not in PDB CCD, provide SMILES manually:\n",
        "    \"LIG1\": \"N[C@@H](CC1CCC(O)CC1)C(O)=O\",  # From mmCIF (cyclohexyl amino acid)\n",
        "}\n",
        "\n",
        "# Manual charge overrides (only needed if Dimorphite-DL fails or for special cases)\n",
        "# Usually not needed since Dimorphite-DL calculates pH-dependent charge\n",
        "MANUAL_CHARGES = {\n",
        "    # \"SAH\": -1,  # Example: override if Dimorphite-DL fails\n",
        "    # \"LIG1\": 0,  # Example: zwitterion\n",
        "}\n",
        "\n",
        "# Check if we have ligand files from previous cell\n",
        "if 'result' in dir() and result.get('ligand_files'):\n",
        "    print(\"Testing NEW workflow: SMILES Template + Dimorphite-DL Protonation\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"Workflow:\")\n",
        "    print(\"  1. Fetch SMILES from PDB CCD API\")\n",
        "    print(\"  2. Apply pH 7.4 protonation (Dimorphite-DL)\")\n",
        "    print(\"  3. Template match → Bond orders → Add H → Optimize → SDF\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    job_dir = Path(result['output_dir'])\n",
        "    \n",
        "    # Store results for later use\n",
        "    ligand_results = []\n",
        "    \n",
        "    for lig_file in result['ligand_files']:\n",
        "        lig_path = Path(lig_file)\n",
        "        if lig_path.exists():\n",
        "            # Extract residue name from filename (e.g., ligand_SAH_chainC.pdb -> SAH)\n",
        "            res_name = lig_path.stem.split('_')[1] if '_' in lig_path.stem else \"UNK\"\n",
        "            \n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Ligand: {lig_path.name} (residue: {res_name})\")\n",
        "            print(f\"{'='*60}\")\n",
        "            \n",
        "            lig_result = {\n",
        "                \"file\": str(lig_path),\n",
        "                \"residue\": res_name,\n",
        "                \"charge\": None,\n",
        "                \"charge_source\": None,\n",
        "                \"sdf_file\": None,\n",
        "                \"smiles_source\": None\n",
        "            }\n",
        "            \n",
        "            try:\n",
        "                # Get manual SMILES/charge if provided\n",
        "                manual_smiles = MANUAL_SMILES.get(res_name)\n",
        "                manual_charge = MANUAL_CHARGES.get(res_name)\n",
        "                \n",
        "                # Use prepare_ligand_for_amber with SMILES template + Dimorphite-DL\n",
        "                print(\"\\n[Step 1] Preparing ligand with SMILES template + pH protonation...\")\n",
        "                if manual_smiles:\n",
        "                    print(f\"  → Using MANUAL SMILES for {res_name}\")\n",
        "                else:\n",
        "                    print(f\"  → Fetching SMILES from PDB CCD API...\")\n",
        "                \n",
        "                prep_result = prepare_ligand_for_amber(\n",
        "                    ligand_pdb=str(lig_path),\n",
        "                    ligand_id=res_name,\n",
        "                    output_dir=str(job_dir),\n",
        "                    smiles=manual_smiles,      # None = fetch from CCD\n",
        "                    fetch_smiles=True,         # Try CCD API\n",
        "                    optimize=True,             # RDKit MMFF94 optimization\n",
        "                    max_opt_iters=200,\n",
        "                    target_ph=7.4,             # Physiological pH for Dimorphite-DL\n",
        "                    manual_charge=manual_charge  # Override charge if needed\n",
        "                )\n",
        "                \n",
        "                print(f\"  ✓ SMILES source: {prep_result['smiles_source']}\")\n",
        "                print(f\"  ✓ Target pH: {prep_result.get('target_ph', 'N/A')}\")\n",
        "                print(f\"  ✓ SDF output: {Path(prep_result['sdf_file']).name}\")\n",
        "                print(f\"  ✓ Atoms: {prep_result['num_atoms']} ({prep_result['num_heavy_atoms']} heavy)\")\n",
        "                print(f\"  ✓ Net charge: {prep_result['net_charge']} (from {prep_result.get('charge_source', 'unknown')})\")\n",
        "                if prep_result.get('mol_formal_charge') is not None:\n",
        "                    print(f\"    - Mol formal charge: {prep_result['mol_formal_charge']}\")\n",
        "                print(f\"  ✓ Optimized: {prep_result['optimized']}\")\n",
        "                if prep_result['optimized']:\n",
        "                    print(f\"  ✓ Optimization converged: {prep_result['optimization_converged']}\")\n",
        "                \n",
        "                # Show SMILES transformation\n",
        "                if prep_result.get('smiles_original') and prep_result.get('smiles_used'):\n",
        "                    print(f\"\\n  SMILES transformation:\")\n",
        "                    print(f\"    Original:   {prep_result['smiles_original'][:50]}...\")\n",
        "                    print(f\"    Protonated: {prep_result['smiles_used'][:50]}...\")\n",
        "                \n",
        "                lig_result[\"sdf_file\"] = prep_result['sdf_file']\n",
        "                lig_result[\"smiles_source\"] = prep_result['smiles_source']\n",
        "                lig_result[\"charge\"] = prep_result['net_charge']\n",
        "                lig_result[\"charge_source\"] = prep_result.get('charge_source', 'dimorphite')\n",
        "                \n",
        "                ligand_results.append(lig_result)\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ Error: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                \n",
        "                # Add failed result for summary\n",
        "                lig_result[\"charge_source\"] = \"failed\"\n",
        "                ligand_results.append(lig_result)\n",
        "        else:\n",
        "            print(f\"  ✗ File not found: {lig_file}\")\n",
        "    \n",
        "    # Summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"LIGAND PREPARATION SUMMARY (SMILES Template + Dimorphite-DL)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for lr in ligand_results:\n",
        "        if lr.get(\"sdf_file\"):\n",
        "            status = \"✓\"\n",
        "            source = f\"(SMILES: {lr['smiles_source']}, charge: {lr['charge_source']})\"\n",
        "        else:\n",
        "            status = \"✗\"\n",
        "            source = \"(FAILED)\"\n",
        "        print(f\"  {status} {lr['residue']}: charge={lr['charge']} {source}\")\n",
        "else:\n",
        "    print(\"No ligand files available. Run previous cell first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 6: Antechamber Force Field Generation\n",
        "\n",
        "Run antechamber to generate GAFF2 parameters with AM1-BCC charges, then validate the frcmod output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test antechamber force field generation (using SDF from SMILES template workflow)\n",
        "run_antechamber_robust = get_callable(amber_module.run_antechamber_robust)\n",
        "validate_frcmod = get_callable(amber_module.validate_frcmod)\n",
        "\n",
        "# Check if we have ligand results from previous cell\n",
        "if 'ligand_results' in dir() and ligand_results:\n",
        "    print(\"Testing Antechamber Force Field Generation (SDF Input)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Using SDF files with correct bond orders from SMILES template\")\n",
        "    \n",
        "    # Store antechamber results\n",
        "    antechamber_results = []\n",
        "    \n",
        "    for lr in ligand_results:\n",
        "        res_name = lr['residue']\n",
        "        sdf_file = lr.get('sdf_file')  # NEW: Use SDF from prepare_ligand_for_amber\n",
        "        charge = lr.get('charge')\n",
        "        \n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Processing: {res_name}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        \n",
        "        if sdf_file is None:\n",
        "            print(f\"  ✗ No SDF file available (SMILES template matching failed)\")\n",
        "            print(f\"     Try providing SMILES manually in MANUAL_SMILES dict\")\n",
        "            continue\n",
        "            \n",
        "        if charge is None:\n",
        "            print(f\"  ✗ No charge specified - skipping\")\n",
        "            print(f\"     Add '{res_name}' to MANUAL_CHARGES dict with appropriate charge\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"  Input: {Path(sdf_file).name} (SDF with correct bond orders)\")\n",
        "        print(f\"  Net charge: {charge}\")\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Run antechamber with SDF input\n",
        "            print(f\"\\n[Step 1] Running antechamber (GAFF2 + AM1-BCC)...\")\n",
        "            print(f\"  This may take a few minutes for large molecules...\")\n",
        "            \n",
        "            ac_result = run_antechamber_robust(\n",
        "                ligand_file=sdf_file,  # SDF input preserves bond orders!\n",
        "                net_charge=charge,\n",
        "                residue_name=res_name[:3].upper(),  # 3-letter code\n",
        "                charge_method=\"bcc\",\n",
        "                atom_type=\"gaff2\"\n",
        "            )\n",
        "            \n",
        "            print(f\"  ✓ MOL2 output: {Path(ac_result['mol2']).name}\")\n",
        "            print(f\"  ✓ FRCMOD output: {Path(ac_result['frcmod']).name}\")\n",
        "            print(f\"  ✓ Charge used: {ac_result['charge_used']}\")\n",
        "            print(f\"  ✓ Total charge (sum): {ac_result['total_charge']:.4f}\")\n",
        "            \n",
        "            # Show sqm diagnostics if available\n",
        "            if ac_result.get('sqm_diagnostics'):\n",
        "                diag = ac_result['sqm_diagnostics']\n",
        "                if diag.get('success'):\n",
        "                    print(f\"  ✓ sqm calculation successful\")\n",
        "                else:\n",
        "                    print(f\"  ⚠ sqm issues: {diag.get('errors', [])}\")\n",
        "            \n",
        "            # Step 2: Validate frcmod\n",
        "            print(f\"\\n[Step 2] Validating frcmod...\")\n",
        "            frcmod_result = validate_frcmod(ac_result['frcmod'])\n",
        "            \n",
        "            if frcmod_result['valid']:\n",
        "                print(f\"  ✓ frcmod validation PASSED\")\n",
        "            else:\n",
        "                print(f\"  ⚠ frcmod validation WARNINGS:\")\n",
        "                print(f\"     ATTN count: {frcmod_result['attn_count']}\")\n",
        "                for w in frcmod_result['warnings'][:3]:\n",
        "                    print(f\"     - {w}\")\n",
        "                if frcmod_result.get('recommendations'):\n",
        "                    print(f\"     Recommendations:\")\n",
        "                    for r in frcmod_result['recommendations'][:2]:\n",
        "                        print(f\"       • {r}\")\n",
        "            \n",
        "            antechamber_results.append({\n",
        "                \"residue\": res_name,\n",
        "                \"mol2\": ac_result['mol2'],\n",
        "                \"frcmod\": ac_result['frcmod'],\n",
        "                \"charge\": ac_result['charge_used'],\n",
        "                \"frcmod_valid\": frcmod_result['valid'],\n",
        "                \"success\": True\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            antechamber_results.append({\n",
        "                \"residue\": res_name,\n",
        "                \"success\": False,\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "    \n",
        "    # Summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"ANTECHAMBER SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    for ar in antechamber_results:\n",
        "        if ar.get('success'):\n",
        "            frcmod_status = \"✓\" if ar.get('frcmod_valid') else \"⚠\"\n",
        "            print(f\"  ✓ {ar['residue']}: charge={ar['charge']}, frcmod={frcmod_status}\")\n",
        "        else:\n",
        "            print(f\"  ✗ {ar['residue']}: FAILED - {ar.get('error', 'unknown')}\")\n",
        "else:\n",
        "    print(\"No ligand results available. Run previous cells first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 7: tleap System Building\n",
        "\n",
        "Build the complete MD system with tleap (protein + ligand + solvent + ions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test tleap system building with ALL ligands\n",
        "# Reload module to get new build_multi_ligand_system function\n",
        "import importlib\n",
        "amber_module = importlib.reload(amber_module)\n",
        "\n",
        "build_multi_ligand_system = get_callable(amber_module.build_multi_ligand_system)\n",
        "prepare_protein_for_amber = get_callable(amber_module.prepare_protein_for_amber)\n",
        "\n",
        "# Check if we have the required files\n",
        "if 'result' in dir() and 'antechamber_results' in dir():\n",
        "    print(\"Testing tleap System Building (ALL LIGANDS)\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    job_dir = Path(result['output_dir'])\n",
        "    protein_pdb = result.get('protein_pdb')\n",
        "    \n",
        "    # Get ALL successful ligand results\n",
        "    # Each ligand now has a unique filename (e.g., SAH_chainC_gaff.mol2)\n",
        "    successful_ligands = []\n",
        "    \n",
        "    for ar in antechamber_results:\n",
        "        if ar.get('success') and ar.get('mol2'):\n",
        "            # Extract residue name from the mol2 filename\n",
        "            # e.g., ligand_SAH_chainC_H.gaff.mol2 -> SAH\n",
        "            mol2_name = Path(ar['mol2']).stem  # e.g., ligand_SAH_chainC_H.gaff\n",
        "            # Remove .gaff suffix if present\n",
        "            if mol2_name.endswith('.gaff'):\n",
        "                mol2_name = mol2_name[:-5]\n",
        "            # Extract residue type (e.g., SAH or LIG1)\n",
        "            parts = mol2_name.split('_')\n",
        "            if len(parts) >= 2 and parts[0] == 'ligand':\n",
        "                resname = parts[1][:3].upper()  # SAH, LIG\n",
        "            else:\n",
        "                resname = ar['residue'][:3].upper()\n",
        "            \n",
        "            successful_ligands.append({\n",
        "                'mol2': ar['mol2'],\n",
        "                'frcmod': ar['frcmod'],\n",
        "                'residue_name': resname\n",
        "            })\n",
        "    \n",
        "    if protein_pdb is None:\n",
        "        print(\"  ✗ No protein PDB available\")\n",
        "    elif not successful_ligands:\n",
        "        print(\"  ✗ No successful ligand parameterization available\")\n",
        "    else:\n",
        "        print(f\"  Protein: {Path(protein_pdb).name}\")\n",
        "        print(f\"  Ligands: {len(successful_ligands)}\")\n",
        "        for i, lig in enumerate(successful_ligands):\n",
        "            print(f\"    [{i+1}] {lig['residue_name']}: {Path(lig['mol2']).name}\")\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Prepare protein with pdb4amber\n",
        "            print(f\"\\n[Step 1] Preparing protein with pdb4amber...\")\n",
        "            protein_result = prepare_protein_for_amber(\n",
        "                protein_pdb,\n",
        "                output_dir=str(job_dir)\n",
        "            )\n",
        "            print(f\"  ✓ Prepared protein: {Path(protein_result['output_pdb']).name}\")\n",
        "            if protein_result.get('disulfide_bonds'):\n",
        "                print(f\"  ✓ Disulfide bonds detected: {len(protein_result['disulfide_bonds'])}\")\n",
        "            \n",
        "            # Step 2: Build system with tleap (ALL LIGANDS)\n",
        "            print(f\"\\n[Step 2] Building MD system with tleap...\")\n",
        "            print(f\"  Including {len(successful_ligands)} ligands\")\n",
        "            print(f\"  Water model: TIP3P\")\n",
        "            print(f\"  Box padding: 10.0 Å\")\n",
        "            print(f\"  Neutralizing with ions...\")\n",
        "            \n",
        "            system_result = build_multi_ligand_system(\n",
        "                protein_pdb=protein_result['output_pdb'],\n",
        "                ligands=successful_ligands,\n",
        "                output_dir=str(job_dir),\n",
        "                forcefield=\"leaprc.protein.ff14SB\",\n",
        "                water_model=\"tip3p\",\n",
        "                box_padding=10.0,\n",
        "                box_type=\"box\",  # cubic box\n",
        "                neutralize=True,\n",
        "                salt_conc=0.0\n",
        "            )\n",
        "            \n",
        "            print(f\"\\n  ✓ System built successfully!\")\n",
        "            print(f\"  ✓ Topology file: {Path(system_result['parm7']).name}\")\n",
        "            print(f\"  ✓ Coordinate file: {Path(system_result['rst7']).name}\")\n",
        "            print(f\"  ✓ Complex PDB: {Path(system_result['complex_pdb']).name}\")\n",
        "            print(f\"  ✓ Ligands included: {system_result.get('num_ligands', len(successful_ligands))}\")\n",
        "            print(f\"    Names: {system_result.get('ligand_names', [l['residue_name'] for l in successful_ligands])}\")\n",
        "            \n",
        "            if system_result.get('num_atoms'):\n",
        "                print(f\"  ✓ Total atoms: {system_result['num_atoms']}\")\n",
        "            if system_result.get('num_residues'):\n",
        "                print(f\"  ✓ Total residues: {system_result['num_residues']}\")\n",
        "            \n",
        "            # Check for warnings\n",
        "            if system_result.get('warnings'):\n",
        "                print(f\"\\n  ⚠ tleap warnings ({len(system_result['warnings'])}):\")\n",
        "                for w in system_result['warnings'][:5]:\n",
        "                    print(f\"     - {w[:80]}...\")\n",
        "            \n",
        "            # Verify output files exist\n",
        "            print(f\"\\n[Step 3] Verifying output files...\")\n",
        "            parm7_path = Path(system_result['parm7'])\n",
        "            rst7_path = Path(system_result['rst7'])\n",
        "            \n",
        "            if parm7_path.exists():\n",
        "                parm7_size = parm7_path.stat().st_size / 1024  # KB\n",
        "                print(f\"  ✓ {parm7_path.name}: {parm7_size:.1f} KB\")\n",
        "            else:\n",
        "                print(f\"  ✗ {parm7_path.name}: NOT FOUND\")\n",
        "            \n",
        "            if rst7_path.exists():\n",
        "                rst7_size = rst7_path.stat().st_size / 1024  # KB\n",
        "                print(f\"  ✓ {rst7_path.name}: {rst7_size:.1f} KB\")\n",
        "            else:\n",
        "                print(f\"  ✗ {rst7_path.name}: NOT FOUND\")\n",
        "            \n",
        "            # Summary\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"SYSTEM BUILDING COMPLETE\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"  Output directory: {system_result['output_dir']}\")\n",
        "            print(f\"  Topology: {system_result['parm7']}\")\n",
        "            print(f\"  Coordinates: {system_result['rst7']}\")\n",
        "            print(f\"  Ligands: {system_result.get('ligand_names', [])}\")\n",
        "            print(f\"\\n  These files are ready for MD simulation with Amber/OpenMM!\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "else:\n",
        "    print(\"Required data not available. Run previous cells first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 8: 3D Visualization with py3Dmol\n",
        "\n",
        "Visualize the built complex with py3Dmol.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize tleap build result: Convert parm7/rst7 to PDB and display\n",
        "import tempfile\n",
        "\n",
        "try:\n",
        "    import mdtraj as md\n",
        "except ImportError:\n",
        "    print(\"Installing MDTraj...\")\n",
        "    %pip install mdtraj\n",
        "    import mdtraj as md\n",
        "\n",
        "try:\n",
        "    import py3Dmol\n",
        "except ImportError:\n",
        "    print(\"Installing py3Dmol...\")\n",
        "    %pip install py3Dmol\n",
        "    import py3Dmol\n",
        "\n",
        "# Check if we have tleap build results\n",
        "if 'system_result' in dir() and system_result.get('parm7') and system_result.get('rst7'):\n",
        "    parm7_path = Path(system_result['parm7'])\n",
        "    rst7_path = Path(system_result['rst7'])\n",
        "    \n",
        "    print(\"=== tleap Build Validation ===\")\n",
        "    print(f\"Topology: {parm7_path.name}\")\n",
        "    print(f\"Coordinates: {rst7_path.name}\")\n",
        "    \n",
        "    if parm7_path.exists() and rst7_path.exists():\n",
        "        # Load coordinates with MDTraj\n",
        "        print(\"\\nLoading system with MDTraj...\")\n",
        "        traj = md.load(str(rst7_path), top=str(parm7_path))\n",
        "        \n",
        "        print(f\"  Total atoms: {traj.n_atoms}\")\n",
        "        print(f\"  Total residues: {traj.n_residues}\")\n",
        "        \n",
        "        # Count residue types\n",
        "        res_counts = {}\n",
        "        ligand_resnames = set()\n",
        "        standard_res = {'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'CYX', 'GLN', 'GLU', \n",
        "                        'GLY', 'HIS', 'HID', 'HIE', 'HIP', 'ILE', 'LEU', 'LYS', \n",
        "                        'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL'}\n",
        "        water_res = {'WAT', 'HOH'}\n",
        "        ion_res = {'NA', 'CL', 'Na+', 'Cl-', 'K', 'K+'}\n",
        "        \n",
        "        for res in traj.topology.residues:\n",
        "            res_counts[res.name] = res_counts.get(res.name, 0) + 1\n",
        "            if res.name not in standard_res and res.name not in water_res and res.name not in ion_res:\n",
        "                ligand_resnames.add(res.name)\n",
        "        \n",
        "        # Print summary\n",
        "        print(f\"\\n  Residue summary:\")\n",
        "        protein_count = sum(res_counts.get(aa, 0) for aa in standard_res)\n",
        "        water_count = sum(res_counts.get(w, 0) for w in water_res)\n",
        "        ion_count = sum(res_counts.get(i, 0) for i in ion_res)\n",
        "        print(f\"    Protein residues: {protein_count}\")\n",
        "        print(f\"    Water molecules: {water_count}\")\n",
        "        print(f\"    Ions: {ion_count}\")\n",
        "        print(f\"    Ligands: {ligand_resnames}\")\n",
        "        for lig in ligand_resnames:\n",
        "            print(f\"      - {lig}: {res_counts.get(lig, 0)}\")\n",
        "        \n",
        "        # Convert to PDB for visualization\n",
        "        print(\"\\nConverting to PDB for visualization...\")\n",
        "        with tempfile.NamedTemporaryFile(suffix='.pdb', delete=False, mode='w') as tmp:\n",
        "            tmp_pdb = tmp.name\n",
        "        traj.save_pdb(tmp_pdb)\n",
        "        \n",
        "        with open(tmp_pdb, 'r') as f:\n",
        "            pdb_content = f.read()\n",
        "        Path(tmp_pdb).unlink()\n",
        "        \n",
        "        # Create viewer\n",
        "        print(\"Creating 3D view...\")\n",
        "        view = py3Dmol.view(width=900, height=700)\n",
        "        view.addModel(pdb_content, 'pdb')\n",
        "        \n",
        "        # Style protein - cartoon\n",
        "        view.setStyle({'resn': list(standard_res)}, \n",
        "                      {'cartoon': {'color': 'spectrum'}})\n",
        "        \n",
        "        # Style ligands - stick with different colors\n",
        "        lig_colors = ['green', 'cyan', 'magenta', 'orange']\n",
        "        for i, resn in enumerate(sorted(ligand_resnames)):\n",
        "            color = lig_colors[i % len(lig_colors)]\n",
        "            view.setStyle({'resn': resn}, \n",
        "                          {'stick': {'color': color, 'radius': 0.3}})\n",
        "            # Add label\n",
        "            view.addResLabels({'resn': resn}, {\n",
        "                'fontSize': 12,\n",
        "                'fontColor': 'white',\n",
        "                'backgroundColor': color,\n",
        "                'backgroundOpacity': 0.8\n",
        "            })\n",
        "        \n",
        "        # Style water - small dots (blue)\n",
        "        view.setStyle({'resn': list(water_res)}, \n",
        "                      {'sphere': {'radius': 0.15, 'color': 'lightblue'}})\n",
        "        \n",
        "        # Style ions - spheres\n",
        "        view.setStyle({'resn': ['NA', 'Na+']}, \n",
        "                      {'sphere': {'radius': 0.8, 'color': 'purple'}})\n",
        "        view.setStyle({'resn': ['CL', 'Cl-']}, \n",
        "                      {'sphere': {'radius': 0.8, 'color': 'yellow'}})\n",
        "        \n",
        "        view.zoomTo()\n",
        "        \n",
        "        # Use orthographic projection\n",
        "        view.setProjection('orthographic')\n",
        "        \n",
        "        # Add box visualization if available\n",
        "        if traj.unitcell_lengths is not None:\n",
        "            box = traj.unitcell_lengths[0] * 10  # nm to Angstrom\n",
        "            print(f\"\\n  Box dimensions: {box[0]:.1f} x {box[1]:.1f} x {box[2]:.1f} Å\")\n",
        "        \n",
        "        print(f\"\\n🔹 Protein ({protein_count} res): Cartoon (spectrum)\")\n",
        "        print(f\"🔹 Ligands {list(ligand_resnames)}: Stick (colored)\")\n",
        "        print(f\"🔹 Water ({water_count} mol): Dots (light blue)\")\n",
        "        print(f\"🔹 Ions ({ion_count}): Spheres (Na+=purple, Cl-=yellow)\")\n",
        "        \n",
        "        view.show()\n",
        "    else:\n",
        "        print(f\"Files not found:\")\n",
        "        print(f\"  parm7: {parm7_path.exists()}\")\n",
        "        print(f\"  rst7: {rst7_path.exists()}\")\n",
        "else:\n",
        "    print(\"No tleap build results available. Run Test 7 first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 9: OpenMM Simulation (Minimize → Equilibrate → Production)\n",
        "\n",
        "Run a minimal MD simulation with OpenMM to verify the system works.\n",
        "- Platform: CUDA > OpenCL (Mac GPU) > CPU\n",
        "- Ensemble: NPT (1 atm, 300 K)\n",
        "- Short run for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OpenMM Simulation: Minimize → Equilibrate → Production\n",
        "import time\n",
        "\n",
        "try:\n",
        "    import openmm as mm\n",
        "    from openmm import app, unit\n",
        "    from openmm.app import PDBFile, AmberPrmtopFile, AmberInpcrdFile\n",
        "    from openmm.app import Simulation, StateDataReporter, DCDReporter\n",
        "except ImportError:\n",
        "    print(\"Installing OpenMM...\")\n",
        "    %pip install openmm\n",
        "    import openmm as mm\n",
        "    from openmm import app, unit\n",
        "    from openmm.app import PDBFile, AmberPrmtopFile, AmberInpcrdFile\n",
        "    from openmm.app import Simulation, StateDataReporter, DCDReporter\n",
        "\n",
        "def select_platform():\n",
        "    \"\"\"Select best available platform: CUDA > OpenCL > CPU\"\"\"\n",
        "    platform_preference = ['CUDA', 'OpenCL', 'CPU']\n",
        "    \n",
        "    print(\"Checking available platforms...\")\n",
        "    for name in platform_preference:\n",
        "        try:\n",
        "            platform = mm.Platform.getPlatformByName(name)\n",
        "            # Test if platform actually works\n",
        "            if name == 'CUDA':\n",
        "                try:\n",
        "                    platform.getPropertyDefaultValue('DeviceIndex')\n",
        "                    print(f\"  ✓ {name} available\")\n",
        "                    return platform, name\n",
        "                except Exception:\n",
        "                    print(f\"  ✗ {name} not available (no GPU)\")\n",
        "                    continue\n",
        "            elif name == 'OpenCL':\n",
        "                print(f\"  ✓ {name} available (Mac GPU)\")\n",
        "                return platform, name\n",
        "            else:\n",
        "                print(f\"  ✓ {name} available\")\n",
        "                return platform, name\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ {name} not available: {e}\")\n",
        "    \n",
        "    raise RuntimeError(\"No suitable platform found!\")\n",
        "\n",
        "# Check if we have the topology/coordinate files\n",
        "if 'system_result' in dir() and system_result.get('parm7') and system_result.get('rst7'):\n",
        "    parm7_path = system_result['parm7']\n",
        "    rst7_path = system_result['rst7']\n",
        "    output_dir = Path(system_result['output_dir'])\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"OpenMM MD Simulation\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Topology: {Path(parm7_path).name}\")\n",
        "    print(f\"Coordinates: {Path(rst7_path).name}\")\n",
        "    \n",
        "    # Select platform\n",
        "    platform, platform_name = select_platform()\n",
        "    print(f\"\\n→ Using platform: {platform_name}\")\n",
        "    \n",
        "    # Simulation parameters\n",
        "    temperature = 300 * unit.kelvin\n",
        "    pressure = 1 * unit.atmosphere\n",
        "    timestep = 2 * unit.femtoseconds\n",
        "    friction = 1 / unit.picosecond\n",
        "    \n",
        "    # Short runs for testing\n",
        "    minimize_max_iter = 500\n",
        "    equil_steps = 2500      # 5 ps equilibration\n",
        "    prod_steps = 5000       # 10 ps production\n",
        "    report_interval = 500   # Report every 1 ps\n",
        "    \n",
        "    print(f\"\\nSimulation parameters:\")\n",
        "    print(f\"  Temperature: {temperature}\")\n",
        "    print(f\"  Pressure: {pressure}\")\n",
        "    print(f\"  Timestep: {timestep}\")\n",
        "    print(f\"  Equilibration: {equil_steps} steps ({equil_steps * 2 / 1000} ps)\")\n",
        "    print(f\"  Production: {prod_steps} steps ({prod_steps * 2 / 1000} ps)\")\n",
        "    \n",
        "    # Load system\n",
        "    print(f\"\\n[Step 1] Loading system...\")\n",
        "    t0 = time.time()\n",
        "    prmtop = AmberPrmtopFile(parm7_path)\n",
        "    inpcrd = AmberInpcrdFile(rst7_path)\n",
        "    print(f\"  ✓ Loaded in {time.time() - t0:.1f}s\")\n",
        "    print(f\"  Atoms: {prmtop.topology.getNumAtoms()}\")\n",
        "    \n",
        "    # Create system\n",
        "    print(f\"\\n[Step 2] Creating OpenMM system...\")\n",
        "    t0 = time.time()\n",
        "    system = prmtop.createSystem(\n",
        "        nonbondedMethod=app.PME,\n",
        "        nonbondedCutoff=10 * unit.angstrom,\n",
        "        constraints=app.HBonds,\n",
        "        rigidWater=True\n",
        "    )\n",
        "    \n",
        "    # Add barostat for NPT\n",
        "    system.addForce(mm.MonteCarloBarostat(pressure, temperature, 25))\n",
        "    print(f\"  ✓ System created in {time.time() - t0:.1f}s\")\n",
        "    \n",
        "    # Create integrator and simulation\n",
        "    integrator = mm.LangevinMiddleIntegrator(temperature, friction, timestep)\n",
        "    simulation = Simulation(prmtop.topology, system, integrator, platform)\n",
        "    simulation.context.setPositions(inpcrd.positions)\n",
        "    \n",
        "    if inpcrd.boxVectors is not None:\n",
        "        simulation.context.setPeriodicBoxVectors(*inpcrd.boxVectors)\n",
        "    \n",
        "    # Energy minimization\n",
        "    print(f\"\\n[Step 3] Energy minimization (max {minimize_max_iter} steps)...\")\n",
        "    t0 = time.time()\n",
        "    state_before = simulation.context.getState(getEnergy=True)\n",
        "    energy_before = state_before.getPotentialEnergy().value_in_unit(unit.kilojoules_per_mole)\n",
        "    \n",
        "    simulation.minimizeEnergy(maxIterations=minimize_max_iter)\n",
        "    \n",
        "    state_after = simulation.context.getState(getEnergy=True)\n",
        "    energy_after = state_after.getPotentialEnergy().value_in_unit(unit.kilojoules_per_mole)\n",
        "    print(f\"  ✓ Minimized in {time.time() - t0:.1f}s\")\n",
        "    print(f\"  Energy: {energy_before:.1f} → {energy_after:.1f} kJ/mol\")\n",
        "    \n",
        "    # Initialize velocities\n",
        "    simulation.context.setVelocitiesToTemperature(temperature)\n",
        "    \n",
        "    # Setup reporters\n",
        "    dcd_file = output_dir / \"trajectory.dcd\"\n",
        "    log_file = output_dir / \"simulation.log\"\n",
        "    \n",
        "    simulation.reporters.append(DCDReporter(str(dcd_file), report_interval))\n",
        "    simulation.reporters.append(StateDataReporter(\n",
        "        str(log_file), report_interval,\n",
        "        step=True, time=True, potentialEnergy=True, kineticEnergy=True,\n",
        "        totalEnergy=True, temperature=True, volume=True, density=True,\n",
        "        speed=True\n",
        "    ))\n",
        "    simulation.reporters.append(StateDataReporter(\n",
        "        sys.stdout, report_interval,\n",
        "        step=True, time=True, temperature=True, speed=True, remainingTime=True,\n",
        "        totalSteps=equil_steps + prod_steps\n",
        "    ))\n",
        "    \n",
        "    # Equilibration (NVT heating is implicit, we go straight to NPT)\n",
        "    print(f\"\\n[Step 4] NPT Equilibration ({equil_steps * 2 / 1000} ps)...\")\n",
        "    t0 = time.time()\n",
        "    simulation.step(equil_steps)\n",
        "    print(f\"  ✓ Equilibration done in {time.time() - t0:.1f}s\")\n",
        "    \n",
        "    # Production\n",
        "    print(f\"\\n[Step 5] Production ({prod_steps * 2 / 1000} ps)...\")\n",
        "    t0 = time.time()\n",
        "    simulation.step(prod_steps)\n",
        "    print(f\"  ✓ Production done in {time.time() - t0:.1f}s\")\n",
        "    \n",
        "    # Save final state\n",
        "    final_pdb = output_dir / \"final_state.pdb\"\n",
        "    state = simulation.context.getState(getPositions=True, getVelocities=True)\n",
        "    with open(final_pdb, 'w') as f:\n",
        "        PDBFile.writeFile(simulation.topology, state.getPositions(), f)\n",
        "    print(f\"\\n✓ Final state saved: {final_pdb.name}\")\n",
        "    \n",
        "    # Summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"SIMULATION COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"  Output directory: {output_dir}\")\n",
        "    print(f\"  Trajectory: {dcd_file.name}\")\n",
        "    print(f\"  Log: {log_file.name}\")\n",
        "    print(f\"  Final PDB: {final_pdb.name}\")\n",
        "    \n",
        "else:\n",
        "    print(\"No topology/coordinate files available. Run system building first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 10: Trajectory Visualization with py3Dmol\n",
        "\n",
        "Visualize the MD trajectory (equilibration + production) with py3Dmol animation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trajectory visualization with py3Dmol\n",
        "# Note: Only LIG1 is in the MD system (SAH was not included in tleap build)\n",
        "import numpy as np\n",
        "import tempfile\n",
        "\n",
        "try:\n",
        "    import mdtraj as md\n",
        "except ImportError:\n",
        "    print(\"Installing MDTraj...\")\n",
        "    %pip install mdtraj\n",
        "    import mdtraj as md\n",
        "\n",
        "import py3Dmol\n",
        "\n",
        "# Check if we have trajectory files\n",
        "if 'system_result' in dir() and system_result.get('output_dir'):\n",
        "    output_dir = Path(system_result['output_dir'])\n",
        "    dcd_file = output_dir / \"trajectory.dcd\"\n",
        "    parm7_file = Path(system_result['parm7'])\n",
        "    \n",
        "    if dcd_file.exists() and parm7_file.exists():\n",
        "        print(\"Loading trajectory...\")\n",
        "        \n",
        "        # Load trajectory with MDTraj\n",
        "        traj = md.load(str(dcd_file), top=str(parm7_file))\n",
        "        print(f\"  Frames: {traj.n_frames}\")\n",
        "        print(f\"  Atoms: {traj.n_atoms}\")\n",
        "        print(f\"  Time: {traj.time[0]:.1f} - {traj.time[-1]:.1f} ps\")\n",
        "        \n",
        "        # Select protein and ligand atoms (exclude water and ions)\n",
        "        protein_indices = traj.topology.select('protein')\n",
        "        \n",
        "        # Find ALL ligand residues (LIG, SAH, or any non-standard non-water residue)\n",
        "        lig_indices = []\n",
        "        ligand_resnames = set()\n",
        "        ligand_details = []  # For debugging\n",
        "        standard_res = {'ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'CYX', 'GLN', 'GLU', \n",
        "                        'GLY', 'HIS', 'HID', 'HIE', 'HIP', 'ILE', 'LEU', 'LYS', \n",
        "                        'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL',\n",
        "                        'WAT', 'HOH', 'NA', 'CL', 'Na+', 'Cl-'}\n",
        "        for residue in traj.topology.residues:\n",
        "            if residue.name not in standard_res:\n",
        "                atom_indices = [atom.index for atom in residue.atoms]\n",
        "                lig_indices.extend(atom_indices)\n",
        "                ligand_resnames.add(residue.name)\n",
        "                ligand_details.append(f\"{residue.name}:{residue.resSeq} ({len(atom_indices)} atoms)\")\n",
        "        lig_indices = np.array(lig_indices) if lig_indices else np.array([], dtype=int)\n",
        "        \n",
        "        # Debug: show all found ligands\n",
        "        print(f\"  Found ligand residues:\")\n",
        "        for detail in ligand_details[:10]:  # Limit output\n",
        "            print(f\"    - {detail}\")\n",
        "        if len(ligand_details) > 10:\n",
        "            print(f\"    ... and {len(ligand_details) - 10} more\")\n",
        "        \n",
        "        # Combine protein + ligand\n",
        "        if len(lig_indices) > 0:\n",
        "            keep_indices = np.concatenate([protein_indices, lig_indices])\n",
        "        else:\n",
        "            keep_indices = protein_indices\n",
        "        \n",
        "        # Remove duplicates and sort\n",
        "        keep_indices = np.unique(keep_indices)\n",
        "        \n",
        "        # Ensure indices are within range\n",
        "        keep_indices = keep_indices[keep_indices < traj.n_atoms]\n",
        "        \n",
        "        print(f\"  Protein atoms: {len(protein_indices)}\")\n",
        "        print(f\"  Ligand atoms: {len(lig_indices)}\")\n",
        "        print(f\"  Ligand types: {ligand_resnames if ligand_resnames else 'None'}\")\n",
        "        print(f\"  Selection atoms: {len(keep_indices)}\")\n",
        "        \n",
        "        # Subset trajectory to protein + ligand only\n",
        "        traj_subset = traj.atom_slice(keep_indices)\n",
        "        print(f\"  Visualization atoms: {traj_subset.n_atoms}\")\n",
        "        \n",
        "        # Sample frames for visualization\n",
        "        max_frames = 15\n",
        "        if traj_subset.n_frames > max_frames:\n",
        "            frame_indices = np.linspace(0, traj_subset.n_frames - 1, max_frames, dtype=int)\n",
        "            traj_viz = traj_subset[frame_indices]\n",
        "            print(f\"  Sampled {max_frames} frames for visualization\")\n",
        "        else:\n",
        "            traj_viz = traj_subset\n",
        "        \n",
        "        print(\"\\nPreparing visualization...\")\n",
        "        \n",
        "        # Save all frames to a single multi-model PDB file\n",
        "        # This is the proper way to do trajectory animation in py3Dmol\n",
        "        with tempfile.NamedTemporaryFile(suffix='.pdb', delete=False, mode='w') as tmp:\n",
        "            tmp_path = tmp.name\n",
        "        \n",
        "        # Write all frames as MODEL/ENDMDL blocks\n",
        "        with open(tmp_path, 'w') as f:\n",
        "            for frame_idx in range(traj_viz.n_frames):\n",
        "                frame = traj_viz[frame_idx]\n",
        "                # Save single frame to temp\n",
        "                frame_tmp = tmp_path + f\".frame{frame_idx}.pdb\"\n",
        "                frame.save_pdb(frame_tmp, force_overwrite=True)\n",
        "                with open(frame_tmp, 'r') as ff:\n",
        "                    content = ff.read()\n",
        "                # Wrap in MODEL/ENDMDL\n",
        "                f.write(f\"MODEL     {frame_idx + 1}\\n\")\n",
        "                # Remove any existing MODEL/ENDMDL lines\n",
        "                for line in content.split('\\n'):\n",
        "                    if not line.startswith('MODEL') and not line.startswith('ENDMDL') and line.strip():\n",
        "                        f.write(line + '\\n')\n",
        "                f.write(\"ENDMDL\\n\")\n",
        "                Path(frame_tmp).unlink()\n",
        "        \n",
        "        # Read the multi-model PDB\n",
        "        with open(tmp_path, 'r') as f:\n",
        "            pdb_content = f.read()\n",
        "        Path(tmp_path).unlink()\n",
        "        \n",
        "        # Create viewer\n",
        "        view = py3Dmol.view(width=800, height=600)\n",
        "        view.addModelsAsFrames(pdb_content, 'pdb')\n",
        "        \n",
        "        # Style - apply to all frames\n",
        "        aa_list = ['ALA', 'ARG', 'ASN', 'ASP', 'CYS', 'CYX', 'GLN', 'GLU', \n",
        "                   'GLY', 'HIS', 'HID', 'HIE', 'HIP', 'ILE', 'LEU', 'LYS', \n",
        "                   'MET', 'PHE', 'PRO', 'SER', 'THR', 'TRP', 'TYR', 'VAL']\n",
        "        \n",
        "        view.setStyle({'resn': aa_list}, {'cartoon': {'color': 'spectrum'}})\n",
        "        \n",
        "        # Style all ligands with different colors and add labels\n",
        "        lig_colors = ['green', 'cyan', 'magenta', 'orange']\n",
        "        for i, resn in enumerate(sorted(ligand_resnames)):\n",
        "            color = lig_colors[i % len(lig_colors)]\n",
        "            view.setStyle({'resn': resn}, {'stick': {'color': color, 'radius': 0.3}})\n",
        "            # Add label for each ligand (at center of residue)\n",
        "            view.addResLabels({'resn': resn}, {\n",
        "                'fontSize': 12,\n",
        "                'fontColor': 'white',\n",
        "                'backgroundColor': color,\n",
        "                'backgroundOpacity': 0.8\n",
        "            })\n",
        "        \n",
        "        view.zoomTo()\n",
        "        \n",
        "        # Use orthographic projection\n",
        "        view.setProjection('orthographic')\n",
        "        \n",
        "        # Enable frame-based animation\n",
        "        view.animate({'loop': 'forward', 'reps': 0, 'interval': 100})\n",
        "        \n",
        "        print(f\"\\n🔹 Protein: Cartoon (spectrum)\")\n",
        "        print(f\"🔹 Ligands: {list(ligand_resnames)} (stick, different colors)\")\n",
        "        print(f\"🔹 Frames: {traj_viz.n_frames} (animated)\")\n",
        "        print(f\"\\n▶️ Animation should auto-play\")\n",
        "        print(f\"   If static, try opening in browser or use nglview instead\")\n",
        "        \n",
        "        view.show()\n",
        "    else:\n",
        "        print(f\"Trajectory file not found: {dcd_file}\")\n",
        "else:\n",
        "    print(\"No simulation results available. Run simulation first.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mcp-md",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
