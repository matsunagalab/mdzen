{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/matsunagalab/mdzen/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Visualize Final Structure\n",
    "\n",
    "View the final frame of the simulation with water molecules wrapped into the periodic box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Install Dependencies\n",
    "\n",
    "**First time only** - This installs AmberTools, OpenMM, and other required packages.\n",
    "\n",
    "‚è±Ô∏è Takes ~2-4 minutes. You can continue reading while it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ‚ñ∂Ô∏è Run Setup (click to expand code)\nimport sys\nimport os\nimport time\nimport socket\nimport subprocess\n\nIN_COLAB = 'google.colab' in sys.modules\n\n#==============================================================================\n# API Key Configuration\n#==============================================================================\n# os.environ['ANTHROPIC_API_KEY'] = 'sk-ant-...'\n#==============================================================================\n\ndef load_dotenv():\n    for env_path in ['./.env', '../.env', '/content/.env', '/content/mdzen/.env']:\n        try:\n            with open(env_path) as f:\n                for line in f:\n                    line = line.strip()\n                    if line and not line.startswith('#') and '=' in line:\n                        key, value = line.split('=', 1)\n                        os.environ[key.strip()] = value.strip().strip('\"').strip(\"'\")\n            return True\n        except FileNotFoundError:\n            continue\n    return False\n\nload_dotenv()\n\nif IN_COLAB:\n    try:\n        from google.colab import userdata\n        for k in ['ANTHROPIC_API_KEY', 'OPENAI_API_KEY', 'GOOGLE_API_KEY']:\n            try:\n                v = userdata.get(k)\n                if v: os.environ[k] = v\n            except: pass\n    except: pass\n\n#==============================================================================\n# Model Auto-Detection\n#==============================================================================\n# Default models (cheap/fast) for each provider\nDEFAULT_MODELS = {\n    'anthropic': ('anthropic:claude-haiku-4-5-20251001', 'anthropic:claude-haiku-4-5-20251001'),\n    'openai': ('openai:gpt-4o-mini', 'openai:gpt-4o-mini'),\n    'google': ('google:gemini-2.0-flash', 'google:gemini-2.0-flash'),\n}\n\n# Detect available API key\ndetected = None\nfor k, p in [('ANTHROPIC_API_KEY', 'anthropic'), ('OPENAI_API_KEY', 'openai'), ('GOOGLE_API_KEY', 'google')]:\n    if os.environ.get(k):\n        detected = p\n        print(f\"‚úì {k}\")\n        break\n\nif detected:\n    clarification_model, setup_model = DEFAULT_MODELS[detected]\n    os.environ['MDZEN_CLARIFICATION_MODEL'] = clarification_model\n    os.environ['MDZEN_SETUP_MODEL'] = setup_model\n    model_name = clarification_model.split(':')[1]\n    print(f\"‚úì Default model: {model_name}\")\nelse:\n    print(\"‚ö†Ô∏è No API key found!\")\n    print(\"   Set one of: ANTHROPIC_API_KEY, OPENAI_API_KEY, GOOGLE_API_KEY\")\n\n#==============================================================================\n# ÂÖ±ÈÄöË®≠ÂÆö: MCP „Çµ„Éº„Éê„ÉºËµ∑Âãï„É≠„Ç∏„ÉÉ„ÇØ\n#==============================================================================\nMCP_SERVERS = [\n    (\"research_server.py\", 8001),\n    (\"structure_server.py\", 8002),\n    (\"genesis_server.py\", 8003),\n    (\"solvation_server.py\", 8004),\n    (\"amber_server.py\", 8005),\n    (\"md_simulation_server.py\", 8006),\n]\n\ndef check_port(port, timeout=2):\n    \"\"\"Check if a port is listening.\"\"\"\n    try:\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(timeout)\n        result = sock.connect_ex(('localhost', port))\n        sock.close()\n        return result == 0\n    except:\n        return False\n\ndef start_mcp_servers(python_cmd, server_dir, pythonpath):\n    \"\"\"Start all MCP servers in HTTP mode.\"\"\"\n    procs = []\n    for server, port in MCP_SERVERS:\n        proc = subprocess.Popen(\n            [python_cmd, f\"{server_dir}/{server}\", \"--http\", \"--port\", str(port)],\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.PIPE,\n            env={**os.environ, \"PYTHONPATH\": pythonpath},\n        )\n        procs.append((server, port, proc))\n    return procs\n\ndef wait_for_servers(procs, max_wait=15):\n    \"\"\"Wait for all servers to be ready.\"\"\"\n    print(\"   Waiting for servers to bind...\")\n    time.sleep(3)\n    waited = 3\n    while waited < max_wait:\n        ready = sum(1 for _, port, proc in procs if check_port(port) and proc.poll() is None)\n        if ready == len(procs):\n            return True\n        time.sleep(1)\n        waited += 1\n    return False\n\ndef report_server_status(procs):\n    \"\"\"Report server health status.\"\"\"\n    healthy = 0\n    failed = []\n    for server, port, proc in procs:\n        if proc.poll() is not None:\n            stderr = proc.stderr.read().decode() if proc.stderr else \"\"\n            err_msg = stderr.split('\\n')[-3:-1] if stderr else [\"Unknown error\"]\n            failed.append((server, port, err_msg))\n            print(f\"   ‚úó {server} (:{port}) - CRASHED\")\n        elif check_port(port):\n            print(f\"   ‚úì {server} (:{port})\")\n            healthy += 1\n        else:\n            print(f\"   ? {server} (:{port}) - NOT RESPONDING\")\n            failed.append((server, port, [\"Port not listening\"]))\n\n    print(f\"‚úì {healthy}/{len(procs)} MCP servers running (Streamable HTTP)\")\n\n    if failed:\n        print(\"\\n‚ö†Ô∏è Server startup errors:\")\n        for server, port, errors in failed:\n            print(f\"   {server}: {' '.join(errors)[:100]}\")\n\n    return healthy\n\n#==============================================================================\n# Áí∞Â¢ÉÂà•„Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó\n#==============================================================================\nif IN_COLAB:\n    start_time = time.time()\n    os.chdir('/content')\n\n    # Install Miniforge\n    print(\"üì¶ Installing Miniforge...\")\n    !curl -fsSL https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh -o /tmp/miniforge.sh\n    !bash /tmp/miniforge.sh -b -p /usr/local -u 2>&1 | tail -1\n    os.environ[\"PATH\"] = f\"/usr/local/bin:{os.environ['PATH']}\"\n    print(f\"‚úì Miniforge ({time.time() - start_time:.0f}s)\")\n\n    # Install scientific packages\n    print(\"‚öóÔ∏è Installing scientific packages...\")\n    !mamba install -y -q openmm pdbfixer parmed ambertools rdkit 2>&1 | tail -2\n    print(f\"‚úì Conda packages ({time.time() - start_time:.0f}s)\")\n\n    # Clone repository\n    print(\"üì• Cloning repository...\")\n    !rm -rf /content/mdzen\n    !git clone -q https://github.com/matsunagalab/mdzen.git /content/mdzen\n    os.chdir('/content/mdzen')\n\n    # Install pip packages\n    print(\"üì¶ Installing Python packages (uv)...\")\n    !pip install -q uv\n\n    CONDA_PYTHON = \"/usr/local/bin/python\"\n    !uv pip install --python {CONDA_PYTHON} -q \\\n        \"litellm>=1.60.0,<1.80.0\" \\\n        anthropic google-genai google-adk \\\n        \"fastmcp>=2.0.0\" \"mcp[cli]\" \\\n        gradio py3Dmol nest_asyncio \\\n        mdtraj gemmi pdb2pqr propka dimorphite-dl \\\n        pubchempy tavily-python\n\n    !uv pip install --python {sys.executable} -q \\\n        py3Dmol nest_asyncio mdtraj \\\n        google-adk litellm anthropic \\\n        \"fastmcp>=2.0.0\" \"mcp[cli]\"\n    print(f\"‚úì Pip packages ({time.time() - start_time:.0f}s)\")\n\n    # Environment setup\n    os.environ[\"AMBERHOME\"] = \"/usr/local\"\n    sys.path.insert(0, '/content/mdzen/src')\n    sys.path.insert(0, '/content/mdzen')\n\n    # Verify imports\n    try:\n        import fastmcp\n        from google.adk.runners import Runner\n        print(\"‚úì Core packages verified\")\n    except ImportError as e:\n        print(f\"‚ö†Ô∏è Import: {e}\")\n\n    # Start MCP servers (Colab)\n    print(\"üöÄ Starting MCP servers...\")\n    PYTHON_CMD = \"/usr/local/bin/python\"\n    SERVER_DIR = \"/content/mdzen/servers\"\n    PYTHONPATH = \"/content/mdzen/src\"\n\n    mcp_procs = start_mcp_servers(PYTHON_CMD, SERVER_DIR, PYTHONPATH)\n    wait_for_servers(mcp_procs)\n    report_server_status(mcp_procs)\n\n    # Suppress async cleanup warnings\n    import logging\n    class F(logging.Filter):\n        def filter(self, r): return 'cancel scope' not in r.getMessage()\n    logging.getLogger('asyncio').addFilter(F())\n\n    print(f\"\\n‚úÖ Setup complete! ({(time.time() - start_time)/60:.1f} min)\")\n\nelse:\n    # Local Jupyter environment\n    sys.path.insert(0, './src')\n    load_dotenv()\n\n    # Start MCP servers (Local)\n    print(\"üöÄ Starting MCP servers (local)...\")\n    PYTHON_CMD = sys.executable\n    SERVER_DIR = \"./servers\"\n    PYTHONPATH = \"./src\"\n\n    mcp_procs = start_mcp_servers(PYTHON_CMD, SERVER_DIR, PYTHONPATH)\n    wait_for_servers(mcp_procs)\n    report_server_status(mcp_procs)\n\n    print(\"\\n‚úÖ Local setup complete!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Describe Your Simulation\n",
    "\n",
    "Tell the AI what you want to simulate in plain language. The AI will ask clarifying questions to help set up the perfect simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title üß¨ Step 1a: Describe Your Simulation { display-mode: \"form\" }\n#@markdown ### What do you want to simulate?\nuser_request = \"I want to run MD simulation of PDB 1AKE (adenylate kinase) in water at 300K for 0.1 ns\" #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown ### Model Selection (optional)\nmodel = \"\" #@param {type:\"string\"}\n#@markdown > Leave empty for auto-detected default. Examples: `gpt-4o-mini`, `claude-haiku`, `gemini-flash`\n\n#@markdown ---\n#@markdown ### Examples (copy one if you like):\n#@markdown - `Setup MD for PDB 1AKE in explicit water, 1 ns at 300K`\n#@markdown - `Simulate lysozyme (1LYZ) with TIP3P water model`\n#@markdown - `Run equilibrium simulation of ubiquitin (1UBQ) at 310K`\n#@markdown - `Setup protein-ligand complex from 3HTB for drug binding study`\n\nimport sys\nimport os\nimport json\nimport random\nimport string\nfrom pathlib import Path\n\n# Initialize session\nIN_COLAB = 'google.colab' in sys.modules\nif 'mdzen_state' not in dir():\n    mdzen_state = {\n        \"session_id\": None, \n        \"session_dir\": None, \n        \"user_request\": None,\n        \"clarification_questions\": None,\n        \"user_answers\": None,\n        \"simulation_brief\": None, \n        \"workflow_outputs\": {},\n        \"model\": None,\n    }\n\ndef init_session():\n    job_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n    base_dir = Path(\"/content/mdzen/outputs\") if IN_COLAB else Path(\"./outputs\")\n    session_dir = base_dir / f\"job_{job_id}\"\n    session_dir.mkdir(parents=True, exist_ok=True)\n    mdzen_state[\"session_id\"] = f\"job_{job_id}\"\n    mdzen_state[\"session_dir\"] = str(session_dir)\n    return session_dir\n\nif mdzen_state[\"session_dir\"] is None:\n    init_session()\n\n# Save user request\nmdzen_state[\"user_request\"] = user_request.strip()\n\n# Handle model selection\ndef normalize_model_name(model_str):\n    \"\"\"Normalize short model names to full provider:model format.\"\"\"\n    if not model_str or not model_str.strip():\n        return None\n    model_str = model_str.strip()\n    \n    # Short aliases\n    aliases = {\n        \"gpt-4o\": \"openai:gpt-4o\",\n        \"gpt-4o-mini\": \"openai:gpt-4o-mini\",\n        \"gpt-4\": \"openai:gpt-4\",\n        \"claude-opus\": \"anthropic:claude-opus-4-5-20251101\",\n        \"claude-sonnet\": \"anthropic:claude-sonnet-4-20250514\",\n        \"claude-haiku\": \"anthropic:claude-haiku-4-5-20251001\",\n        \"gemini-pro\": \"google:gemini-pro\",\n        \"gemini-flash\": \"google:gemini-2.0-flash\",\n    }\n    \n    if model_str.lower() in aliases:\n        return aliases[model_str.lower()]\n    elif \":\" in model_str:\n        return model_str  # Already in provider:model format\n    elif model_str.startswith(\"gpt\"):\n        return f\"openai:{model_str}\"\n    elif model_str.startswith(\"claude\"):\n        return f\"anthropic:{model_str}\"\n    elif model_str.startswith(\"gemini\"):\n        return f\"google:{model_str}\"\n    else:\n        return model_str\n\nif model.strip():\n    normalized = normalize_model_name(model)\n    if normalized:\n        os.environ['MDZEN_CLARIFICATION_MODEL'] = normalized\n        os.environ['MDZEN_SETUP_MODEL'] = normalized\n        mdzen_state[\"model\"] = normalized\n        \n        # Reload config settings\n        try:\n            from mdzen import config\n            config.settings = config.Settings()\n        except:\n            pass\n\nprint(\"=\" * 60)\nprint(\"  ‚úÖ Request Received!\")\nprint(\"=\" * 60)\nprint(f\"  üìù \\\"{user_request}\\\"\")\nif mdzen_state.get(\"model\"):\n    print(f\"  ü§ñ Model: {mdzen_state['model']}\")\nelse:\n    current_model = os.environ.get('MDZEN_CLARIFICATION_MODEL', 'auto-detected')\n    print(f\"  ü§ñ Model: {current_model}\")\nprint(\"=\" * 60)\nprint(f\"\\nüìÅ Session: {mdzen_state['session_id']}\")\nprint(\"\\nüëâ Run the next cell to get AI clarification questions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ü§ñ Step 1b: Structure Analysis & Clarification { display-mode: \"form\" }\n#@markdown Analyzes structure and generates clarification questions.\n\nimport json\nfrom pathlib import Path\n\nif 'mdzen_state' not in dir() or not mdzen_state.get(\"user_request\"):\n    print(\"‚ùå Error: Please run Step 1a first\")\nelse:\n    user_request = mdzen_state[\"user_request\"]\n    session_dir = mdzen_state[\"session_dir\"]\n    \n    # Reload config to pick up any model changes\n    from mdzen import config\n    config.settings = config.Settings()\n    current_model = config.settings.clarification_model\n    \n    print(\"ü§ñ Starting clarification agent (Streamable HTTP)...\")\n    print(f\"   Model: {current_model}\")\n    print(\"-\" * 60)\n    \n    from mdzen.agents.clarification_agent import create_clarification_agent\n    from mdzen.tools.mcp_setup import close_toolsets\n    from google.adk.runners import Runner\n    from google.adk.sessions import InMemorySessionService\n    from google.genai import types\n    \n    # Use Streamable HTTP transport (more reliable in Colab)\n    agent, mcp_tools = create_clarification_agent(transport=\"http\")\n    \n    session_service = InMemorySessionService()\n    runner = Runner(\n        app_name=\"mdzen\",\n        agent=agent,\n        session_service=session_service,\n    )\n    \n    async def run_clarification():\n        session = await session_service.create_session(\n            app_name=\"mdzen\",\n            user_id=\"colab_user\",\n            state={\"session_dir\": session_dir},\n        )\n        \n        message = types.Content(\n            role=\"user\",\n            parts=[types.Part(text=user_request)],\n        )\n        \n        final_response = None\n        async for event in runner.run_async(\n            user_id=\"colab_user\",\n            session_id=session.id,\n            new_message=message,\n        ):\n            if event.is_final_response() and event.content:\n                final_response = event.content.parts[0].text if event.content.parts else None\n        \n        updated_session = await session_service.get_session(\n            app_name=\"mdzen\",\n            user_id=\"colab_user\",\n            session_id=session.id,\n        )\n        \n        return final_response, updated_session.state\n    \n    try:\n        final_response, session_state = await run_clarification()\n        await close_toolsets(mcp_tools)\n        \n        if session_state.get(\"simulation_brief\"):\n            brief = session_state[\"simulation_brief\"]\n            if isinstance(brief, str):\n                try:\n                    brief = json.loads(brief)\n                except:\n                    pass\n            \n            if isinstance(brief, dict):\n                mdzen_state[\"simulation_brief\"] = brief\n                print(\"\\n‚úÖ SimulationBrief Generated!\")\n                print(\"-\" * 60)\n                for key, val in brief.items():\n                    if val is not None:\n                        print(f\"   ‚Ä¢ {key}: {val}\")\n                print(\"\\nüëâ Proceed to Step 1d to review\")\n            else:\n                mdzen_state[\"agent_questions\"] = brief\n                print(\"\\nü§ñ Agent needs more information:\")\n                print(\"-\" * 60)\n                print(brief)\n                print(\"\\nüëâ Answer in Step 1c\")\n        else:\n            if final_response:\n                mdzen_state[\"agent_questions\"] = final_response\n            print(\"\\nü§ñ Agent response:\")\n            print(final_response or \"No response\")\n            print(\"\\nüëâ Answer in Step 1c\")\n            \n    except Exception as e:\n        import traceback\n        print(f\"‚ùå Error: {e}\")\n        traceback.print_exc()\n        try:\n            await close_toolsets(mcp_tools)\n        except:\n            pass"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title üí¨ Step 1c: Conversation with Agent { display-mode: \"form\" }\n#@markdown ### Your Response\nuser_response = \"\" #@param {type:\"string\"}\n#@markdown Re-run this cell as many times as needed until SimulationBrief is generated.\n\nimport json\n\nif 'mdzen_state' not in dir():\n    print(\"‚ùå Error: Please run Step 1a first\")\nelif not user_response.strip():\n    if mdzen_state.get(\"simulation_brief\") and isinstance(mdzen_state[\"simulation_brief\"], dict):\n        print(\"‚úÖ SimulationBrief already generated! Proceed to Step 1d.\")\n        brief = mdzen_state[\"simulation_brief\"]\n        print(f\"   ‚Ä¢ PDB: {brief.get('pdb_id')} | Chains: {brief.get('select_chains')}\")\n    elif mdzen_state.get(\"agent_questions\"):\n        print(\"ü§ñ Agent's questions:\")\n        print(\"-\" * 50)\n        print(mdzen_state[\"agent_questions\"])\n        print(\"-\" * 50)\n        print(\"\\nüëÜ Enter your response above and re-run\")\n    else:\n        print(\"‚ö†Ô∏è Run Step 1b first\")\nelse:\n    print(f\"üí¨ Your response: {user_response}\")\n    print(\"-\" * 50)\n    \n    # Reload config to pick up any model changes\n    from mdzen import config\n    config.settings = config.Settings()\n    \n    from mdzen.agents.clarification_agent import create_clarification_agent\n    from mdzen.tools.mcp_setup import close_toolsets\n    from google.adk.runners import Runner\n    from google.adk.sessions import InMemorySessionService\n    from google.genai import types\n    \n    session_dir = mdzen_state[\"session_dir\"]\n    original_request = mdzen_state.get(\"user_request\", \"\")\n    previous_context = mdzen_state.get(\"agent_questions\", \"\")\n    \n    context_message = f\"\"\"Original request: {original_request}\n\nYour previous analysis: {previous_context}\n\nUser's response: {user_response}\n\nBased on this, either ask follow-up questions OR call generate_simulation_brief with appropriate parameters.\nCRITICAL: You must ACTUALLY CALL the tool, not just say you did.\"\"\"\n    \n    # Use HTTP transport\n    agent, mcp_tools = create_clarification_agent(transport=\"http\")\n    session_service = InMemorySessionService()\n    runner = Runner(app_name=\"mdzen\", agent=agent, session_service=session_service)\n    \n    async def run_conversation():\n        session = await session_service.create_session(\n            app_name=\"mdzen\", user_id=\"colab_user\",\n            state={\"session_dir\": session_dir},\n        )\n        message = types.Content(role=\"user\", parts=[types.Part(text=context_message)])\n        \n        print(\"üîÑ Agent thinking...\")\n        final_response = None\n        async for event in runner.run_async(user_id=\"colab_user\", session_id=session.id, new_message=message):\n            if event.is_final_response() and event.content:\n                final_response = event.content.parts[0].text if event.content.parts else None\n        \n        updated = await session_service.get_session(app_name=\"mdzen\", user_id=\"colab_user\", session_id=session.id)\n        return final_response, updated.state\n    \n    try:\n        final_response, session_state = await run_conversation()\n        await close_toolsets(mcp_tools)\n        \n        if session_state.get(\"simulation_brief\"):\n            brief = session_state[\"simulation_brief\"]\n            if isinstance(brief, str):\n                try: brief = json.loads(brief)\n                except: pass\n            \n            if isinstance(brief, dict):\n                mdzen_state[\"simulation_brief\"] = brief\n                print(\"\\n\" + \"=\" * 50)\n                print(\"‚úÖ SimulationBrief Generated!\")\n                print(\"=\" * 50)\n                print(f\"   ‚Ä¢ PDB: {brief.get('pdb_id')} | Chains: {brief.get('select_chains')}\")\n                print(f\"   ‚Ä¢ Temp: {brief.get('temperature')}K | Time: {brief.get('simulation_time_ns')}ns\")\n                print(\"\\nüëâ Proceed to Step 1d\")\n            else:\n                mdzen_state[\"agent_questions\"] = str(brief)\n                print(\"\\nü§ñ Agent response:\")\n                print(brief)\n        else:\n            mdzen_state[\"agent_questions\"] = final_response\n            print(\"\\nü§ñ Agent response:\")\n            print(final_response or \"No response\")\n            print(\"\\nüëÜ Enter response above and re-run\")\n            \n    except Exception as e:\n        import traceback\n        print(f\"‚ùå Error: {e}\")\n        traceback.print_exc()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ‚úÖ Step 1d: Review & Modify SimulationBrief { display-mode: \"form\" }\n#@markdown ### Current SimulationBrief\n#@markdown Run this cell to see the current configuration.\n#@markdown \n#@markdown ---\n#@markdown ### Modifications (optional)\n#@markdown Describe any changes you want (leave empty to keep current):\nmodifications = \"\" #@param {type:\"string\"}\n#@markdown \n#@markdown **Examples:**\n#@markdown - `Change temperature to 310K`\n#@markdown - `Use 0.5 ns simulation time`\n#@markdown - `Remove pressure (NVT ensemble)`\n\nimport json\n\nif 'mdzen_state' not in dir():\n    print(\"‚ùå Error: Please run Step 1a first\")\nelif not mdzen_state.get(\"simulation_brief\"):\n    print(\"‚ùå Error: No SimulationBrief found\")\n    print(\"   Please run Step 1b and 1c first to generate the brief.\")\nelse:\n    brief = mdzen_state[\"simulation_brief\"]\n    \n    # Display current brief\n    print(\"üìã Current SimulationBrief:\")\n    print(\"=\" * 50)\n    \n    # Group parameters by category\n    structure_keys = ['pdb_id', 'fasta_sequence', 'select_chains', 'structure_file']\n    ligand_keys = ['ligand_smiles', 'charge_method', 'atom_type']\n    solvation_keys = ['water_model', 'box_padding', 'salt_concentration', 'cubic_box', \n                      'cation_type', 'anion_type', 'is_membrane', 'lipids', 'lipid_ratio']\n    simulation_keys = ['temperature', 'pressure_bar', 'simulation_time_ns', 'timestep',\n                       'minimize_steps', 'nonbonded_cutoff', 'constraints', 'output_frequency_ps']\n    forcefield_keys = ['force_field', 'ph', 'cap_termini', 'include_types']\n    \n    def print_section(title, keys):\n        print(f\"\\n{title}:\")\n        for key in keys:\n            if key in brief and brief[key] is not None:\n                val = brief[key]\n                if isinstance(val, list):\n                    val = \", \".join(str(v) for v in val)\n                elif isinstance(val, dict):\n                    val = json.dumps(val)\n                print(f\"  ‚Ä¢ {key}: {val}\")\n    \n    print_section(\"üì¶ Structure\", structure_keys)\n    print_section(\"üíä Ligand\", ligand_keys)\n    print_section(\"üíß Solvation\", solvation_keys)\n    print_section(\"üå°Ô∏è Simulation\", simulation_keys)\n    print_section(\"‚öóÔ∏è Force Field\", forcefield_keys)\n    \n    print(\"\\n\" + \"=\" * 50)\n    \n    # Handle modifications\n    if modifications.strip():\n        print(f\"\\nüîÑ Applying modifications: {modifications}\")\n        print(\"-\" * 50)\n        \n        # Reload config to pick up any model changes\n        from mdzen import config\n        config.settings = config.Settings()\n        \n        # Import necessary modules\n        from mdzen.agents.clarification_agent import create_clarification_agent\n        from mdzen.tools.mcp_setup import close_toolsets\n        from google.adk.runners import Runner\n        from google.adk.sessions import InMemorySessionService\n        from google.genai import types\n        \n        session_dir = mdzen_state[\"session_dir\"]\n        \n        # Create agent\n        agent, mcp_tools = create_clarification_agent(transport=\"http\")\n        session_service = InMemorySessionService()\n        runner = Runner(\n            app_name=\"mdzen\",\n            agent=agent,\n            session_service=session_service,\n        )\n        \n        async def apply_modifications():\n            session = await session_service.create_session(\n                app_name=\"mdzen\",\n                user_id=\"colab_user\",\n                state={\"session_dir\": session_dir, \"simulation_brief\": brief},\n            )\n            \n            # Ask agent to modify the brief\n            modify_prompt = f\"\"\"The current SimulationBrief is:\n{json.dumps(brief, indent=2)}\n\nThe user wants to make these modifications:\n{modifications}\n\nPlease call generate_simulation_brief with the updated parameters.\nKeep all other parameters the same unless the user's modification affects them.\"\"\"\n            \n            message = types.Content(\n                role=\"user\",\n                parts=[types.Part(text=modify_prompt)],\n            )\n            \n            final_response = None\n            async for event in runner.run_async(\n                user_id=\"colab_user\",\n                session_id=session.id,\n                new_message=message,\n            ):\n                if event.is_final_response() and event.content:\n                    final_response = event.content.parts[0].text if event.content.parts else None\n            \n            updated_session = await session_service.get_session(\n                app_name=\"mdzen\",\n                user_id=\"colab_user\",\n                session_id=session.id,\n            )\n            \n            return final_response, updated_session.state\n        \n        try:\n            final_response, session_state = await apply_modifications()\n            await close_toolsets(mcp_tools)\n            \n            if session_state.get(\"simulation_brief\"):\n                new_brief = session_state[\"simulation_brief\"]\n                if isinstance(new_brief, str):\n                    try:\n                        new_brief = json.loads(new_brief)\n                    except:\n                        pass\n                \n                if isinstance(new_brief, dict):\n                    mdzen_state[\"simulation_brief\"] = new_brief\n                    print(\"\\n‚úÖ SimulationBrief updated!\")\n                    print(\"-\" * 50)\n                    \n                    # Show changes\n                    for key in new_brief:\n                        if key in brief and new_brief[key] != brief[key]:\n                            print(f\"  ‚úì {key}: {brief[key]} ‚Üí {new_brief[key]}\")\n                    \n                    print(\"\\nüëâ Run this cell again to see the full updated brief\")\n                else:\n                    print(f\"\\nü§ñ Agent response: {new_brief[:500] if len(str(new_brief)) > 500 else new_brief}\")\n            else:\n                print(f\"\\nü§ñ Agent response: {final_response[:500] if final_response else 'No response'}\")\n                \n        except Exception as e:\n            import traceback\n            print(f\"\\n‚ùå Error: {e}\")\n            traceback.print_exc()\n            try:\n                await close_toolsets(mcp_tools)\n            except:\n                pass\n    else:\n        print(\"\\n‚úÖ Ready for Step 2!\")\n        print(\"   No modifications requested. Proceed to Step 2 to run the MD workflow.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Run MD Workflow\n",
    "\n",
    "This will execute all 4 steps automatically:\n",
    "1. **prepare_complex** - Download structure and prepare proteins/ligands\n",
    "2. **solvate** - Add water box and ions  \n",
    "3. **build_topology** - Generate Amber topology files\n",
    "4. **run_simulation** - Run MD with OpenMM\n",
    "\n",
    "Click ‚ñ∂Ô∏è to start. Progress will be shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title ‚öôÔ∏è Step 2: Run Complete Workflow { display-mode: \"form\" }\n#@markdown ### Run Options\nrun_simulation_step = True #@param {type:\"boolean\"}\n#@markdown > Uncheck to skip the MD simulation (for testing setup only)\n\nimport sys\nimport os\nimport json\nimport traceback\nimport socket\nimport subprocess\nimport time\nfrom pathlib import Path\n\nIN_COLAB = 'google.colab' in sys.modules\n\nif 'mdzen_state' not in dir() or not mdzen_state.get(\"simulation_brief\"):\n    print(\"‚ùå Error: Please run Step 1 first to configure your simulation\")\nelse:\n    brief = mdzen_state[\"simulation_brief\"]\n    session_dir = Path(mdzen_state[\"session_dir\"])\n    \n    #==========================================================================\n    # Server Health Check and Restart\n    #==========================================================================\n    # All 6 servers needed by setup agent\n    MCP_SERVERS = [\n        (\"research_server.py\", 8001),\n        (\"structure_server.py\", 8002),\n        (\"genesis_server.py\", 8003),\n        (\"solvation_server.py\", 8004),\n        (\"amber_server.py\", 8005),\n        (\"md_simulation_server.py\", 8006),\n    ]\n    \n    def check_port(port, timeout=2):\n        try:\n            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            sock.settimeout(timeout)\n            result = sock.connect_ex(('localhost', port))\n            sock.close()\n            return result == 0\n        except:\n            return False\n    \n    def restart_server(server, port, python_cmd, server_dir, pythonpath):\n        \"\"\"Start a single MCP server.\"\"\"\n        proc = subprocess.Popen(\n            [python_cmd, f\"{server_dir}/{server}\", \"--http\", \"--port\", str(port)],\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.PIPE,\n            env={**os.environ, \"PYTHONPATH\": pythonpath},\n        )\n        return proc\n    \n    # Check and restart servers\n    print(\"üîç Checking MCP server health...\")\n    \n    if IN_COLAB:\n        PYTHON_CMD = \"/usr/local/bin/python\"\n        SERVER_DIR = \"/content/mdzen/servers\"\n        PYTHONPATH = \"/content/mdzen/src\"\n    else:\n        PYTHON_CMD = sys.executable\n        SERVER_DIR = \"./servers\"\n        PYTHONPATH = \"./src\"\n    \n    servers_restarted = 0\n    for server, port in MCP_SERVERS:\n        if not check_port(port):\n            print(f\"   ‚ö†Ô∏è {server} (:{port}) not responding, restarting...\")\n            restart_server(server, port, PYTHON_CMD, SERVER_DIR, PYTHONPATH)\n            servers_restarted += 1\n        else:\n            print(f\"   ‚úì {server} (:{port})\")\n    \n    if servers_restarted > 0:\n        print(f\"   Waiting for {servers_restarted} servers to start...\")\n        time.sleep(5)\n        # Verify all servers are up\n        all_up = all(check_port(port) for _, port in MCP_SERVERS)\n        if all_up:\n            print(f\"   ‚úì All {len(MCP_SERVERS)} servers ready\")\n        else:\n            print(\"   ‚ö†Ô∏è Some servers may still be starting, waiting more...\")\n            time.sleep(5)\n    \n    #==========================================================================\n    # Reload config and run workflow\n    #==========================================================================\n    from mdzen import config\n    config.settings = config.Settings()\n    current_model = config.settings.setup_model\n    \n    print(\"=\" * 60)\n    print(f\"  üöÄ Starting MD Workflow for {brief.get('pdb_id', 'Unknown')}\")\n    print(f\"  ü§ñ Model: {current_model}\")\n    print(\"  üì° Using Streamable HTTP transport\")\n    print(\"=\" * 60)\n    \n    from mdzen.agents.setup_agent import create_setup_agent\n    from mdzen.tools.mcp_setup import close_toolsets\n    \n    from google.adk.runners import Runner\n    from google.adk.sessions import InMemorySessionService\n    from google.genai import types\n    \n    async def run_setup():\n        # Create agent with HTTP transport\n        print(\"\\nüîß Creating setup agent (HTTP)...\")\n        agent, mcp_tools = create_setup_agent(transport=\"http\")\n        \n        session_service = InMemorySessionService()\n        runner = Runner(\n            app_name=\"mdzen\",\n            agent=agent,\n            session_service=session_service,\n        )\n        \n        initial_state = {\n            \"session_dir\": str(session_dir),\n            \"simulation_brief\": json.dumps(brief) if isinstance(brief, dict) else brief,\n            \"completed_steps\": json.dumps([]),\n            \"outputs\": json.dumps({}),\n        }\n        \n        session = await session_service.create_session(\n            app_name=\"mdzen\",\n            user_id=\"colab_user\",\n            state=initial_state,\n        )\n        \n        steps_to_run = [\"prepare_complex\", \"solvate\", \"build_topology\"]\n        if run_simulation_step:\n            steps_to_run.append(\"run_simulation\")\n        \n        request = f\"\"\"Execute the MD setup workflow with the following SimulationBrief:\n\n{json.dumps(brief, indent=2)}\n\nPlease run these steps in order: {', '.join(steps_to_run)}\n\nWork in the directory: {session_dir}\n\"\"\"\n        \n        message = types.Content(\n            role=\"user\",\n            parts=[types.Part(text=request)],\n        )\n        \n        print(\"\\nü§ñ Setup agent is running...\")\n        print(\"   (This may take several minutes)\")\n        print(\"-\" * 60)\n        \n        final_response = None\n        async for event in runner.run_async(\n            user_id=\"colab_user\",\n            session_id=session.id,\n            new_message=message,\n        ):\n            if event.content and event.content.parts:\n                text = event.content.parts[0].text if hasattr(event.content.parts[0], 'text') else None\n                if text and not event.is_final_response():\n                    if any(kw in text.lower() for kw in ['step', 'complete', 'running', 'preparing', 'building']):\n                        print(f\"   {text[:200]}...\")\n                \n            if event.is_final_response() and event.content:\n                final_response = event.content.parts[0].text if event.content.parts else None\n        \n        updated_session = await session_service.get_session(\n            app_name=\"mdzen\",\n            user_id=\"colab_user\",\n            session_id=session.id,\n        )\n        \n        return final_response, updated_session.state, mcp_tools\n    \n    try:\n        start_time = time.time()\n        final_response, session_state, mcp_tools = await run_setup()\n        await close_toolsets(mcp_tools)\n        elapsed = time.time() - start_time\n        \n        outputs = session_state.get(\"outputs\", {})\n        if isinstance(outputs, str):\n            try: outputs = json.loads(outputs)\n            except: outputs = {}\n        \n        completed = session_state.get(\"completed_steps\", [])\n        if isinstance(completed, str):\n            try: completed = json.loads(completed)\n            except: completed = []\n        \n        mdzen_state[\"workflow_outputs\"] = outputs\n        \n        print()\n        print(\"=\" * 60)\n        print(\"  üéâ Workflow Complete!\")\n        print(\"=\" * 60)\n        print(f\"  ‚è±Ô∏è Time: {elapsed/60:.1f} min\")\n        print(f\"  ‚úÖ Steps completed: {', '.join(completed) if completed else 'None'}\")\n        print(f\"  üìÅ Output: {session_dir}\")\n        \n        if outputs:\n            print()\n            print(\"  üì¶ Generated files:\")\n            for key, path in outputs.items():\n                if path:\n                    print(f\"     ‚Ä¢ {key}: {Path(path).name if isinstance(path, str) else path}\")\n        \n        print()\n        if final_response:\n            print(\"  üìù Agent summary:\")\n            summary = final_response[:500] + \"...\" if len(final_response) > 500 else final_response\n            for line in summary.split('\\n'):\n                print(f\"     {line}\")\n        \n        print()\n        print(\"  üëâ Run the next cell to visualize the trajectory\")\n        \n    except Exception as e:\n        print()\n        print(\"=\" * 60)\n        print(f\"  ‚ùå Error: {e}\")\n        print(\"=\" * 60)\n        print(traceback.format_exc())\n        print()\n        print(\"  üí° Tip: If servers crashed, try re-running this cell.\")\n        print(\"     The server health check will restart them automatically.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Visualize Results\n",
    "\n",
    "View the trajectory animation with py3Dmol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üî¨ Step 3: Visualize Final Structure { display-mode: \"form\" }\n",
    "#@markdown ### Visualization Options\n",
    "style = \"cartoon\" #@param [\"cartoon\", \"stick\", \"sphere\", \"line\"]\n",
    "show_water = True #@param {type:\"boolean\"}\n",
    "#@markdown > Show water molecules (wrapped into periodic box)\n",
    "\n",
    "import py3Dmol\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "if 'mdzen_state' not in dir() or not mdzen_state.get(\"workflow_outputs\"):\n",
    "    print(\"‚ùå Error: Please run the workflow first (Step 2)\")\n",
    "elif 'trajectory' not in mdzen_state[\"workflow_outputs\"]:\n",
    "    print(\"‚ùå Error: No trajectory found. Make sure 'Run simulation' was checked in Step 2\")\n",
    "else:\n",
    "    print(\"üìä Loading final frame...\")\n",
    "    \n",
    "    import mdtraj as md\n",
    "    traj = md.load(\n",
    "        mdzen_state[\"workflow_outputs\"]['trajectory'], \n",
    "        top=mdzen_state[\"workflow_outputs\"]['parm7']\n",
    "    )\n",
    "    \n",
    "    # Get final frame\n",
    "    final_frame = traj[-1]\n",
    "    \n",
    "    # Image molecules (wrap into periodic box)\n",
    "    final_frame.image_molecules(inplace=True)\n",
    "    \n",
    "    print(f\"   Trajectory: {traj.n_frames} frames, {traj.time[-1]:.1f} ps total\")\n",
    "    print(f\"   Showing: Final frame (t = {final_frame.time[0]:.1f} ps)\")\n",
    "    \n",
    "    # Select atoms to display\n",
    "    if show_water:\n",
    "        # All atoms (protein + water + ions)\n",
    "        display_frame = final_frame\n",
    "        atom_info = f\"{final_frame.n_atoms} atoms (protein + solvent)\"\n",
    "    else:\n",
    "        # Protein only\n",
    "        protein_indices = final_frame.topology.select('protein')\n",
    "        display_frame = final_frame.atom_slice(protein_indices)\n",
    "        atom_info = f\"{display_frame.n_atoms} protein atoms\"\n",
    "    \n",
    "    print(f\"   Atoms: {atom_info}\")\n",
    "    \n",
    "    # Save to temporary PDB\n",
    "    with tempfile.NamedTemporaryFile(suffix='.pdb', delete=False, mode='w') as tmp:\n",
    "        display_frame.save_pdb(tmp.name, force_overwrite=True)\n",
    "        tmp_path = tmp.name\n",
    "    \n",
    "    # Read PDB content\n",
    "    with open(tmp_path) as f:\n",
    "        pdb_content = f.read()\n",
    "    \n",
    "    # Create viewer\n",
    "    view = py3Dmol.view(width=800, height=500)\n",
    "    view.addModel(pdb_content, 'pdb')\n",
    "    \n",
    "    # Apply style based on selection\n",
    "    if show_water:\n",
    "        # Protein in cartoon, water as small spheres\n",
    "        if style == \"cartoon\":\n",
    "            view.setStyle({'protein': True}, {'cartoon': {'color': 'spectrum'}})\n",
    "        elif style == \"stick\":\n",
    "            view.setStyle({'protein': True}, {'stick': {}})\n",
    "        elif style == \"sphere\":\n",
    "            view.setStyle({'protein': True}, {'sphere': {'radius': 0.5}})\n",
    "        else:\n",
    "            view.setStyle({'protein': True}, {'line': {}})\n",
    "        \n",
    "        # Water as small blue spheres\n",
    "        view.setStyle({'resn': 'WAT'}, {'sphere': {'radius': 0.15, 'color': 'lightblue'}})\n",
    "        view.setStyle({'resn': 'HOH'}, {'sphere': {'radius': 0.15, 'color': 'lightblue'}})\n",
    "        \n",
    "        # Ions as spheres\n",
    "        view.setStyle({'elem': 'Na'}, {'sphere': {'radius': 0.3, 'color': 'purple'}})\n",
    "        view.setStyle({'elem': 'Cl'}, {'sphere': {'radius': 0.35, 'color': 'green'}})\n",
    "    else:\n",
    "        # Protein only\n",
    "        if style == \"cartoon\":\n",
    "            view.setStyle({'cartoon': {'color': 'spectrum'}})\n",
    "        elif style == \"stick\":\n",
    "            view.setStyle({'stick': {}})\n",
    "        elif style == \"sphere\":\n",
    "            view.setStyle({'sphere': {'radius': 0.5}})\n",
    "        else:\n",
    "            view.setStyle({'line': {}})\n",
    "    \n",
    "    view.zoomTo()\n",
    "    \n",
    "    # Cleanup temp file\n",
    "    Path(tmp_path).unlink()\n",
    "    \n",
    "    print()\n",
    "    print(\"‚úÖ Final structure displayed\")\n",
    "    print(f\"   Style: {style}\" + (\" + water\" if show_water else \"\"))\n",
    "    print()\n",
    "    print(\"üëâ Run the next cell to download all files\")\n",
    "    \n",
    "    view.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Download Results\n",
    "\n",
    "Download all generated files as a ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì• Step 4: Download Results { display-mode: \"form\" }\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if 'mdzen_state' not in dir() or not mdzen_state.get(\"session_dir\"):\n",
    "    print(\"‚ùå Error: Please run the workflow first\")\n",
    "else:\n",
    "    session_dir = Path(mdzen_state[\"session_dir\"])\n",
    "    \n",
    "    if not session_dir.exists():\n",
    "        print(\"‚ùå Error: Session directory not found\")\n",
    "    else:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"  üìÇ {session_dir.name}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        files = sorted(session_dir.rglob('*'))\n",
    "        total_size = 0\n",
    "        \n",
    "        for f in files:\n",
    "            if f.is_file():\n",
    "                size = f.stat().st_size\n",
    "                total_size += size\n",
    "                size_str = f\"{size/1024:.1f} KB\" if size > 1024 else f\"{size} B\"\n",
    "                print(f\"  {f.relative_to(session_dir):<40} {size_str:>10}\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        print(f\"  Total: {total_size/1024/1024:.2f} MB\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if 'google.colab' in sys.modules:\n",
    "            from google.colab import files\n",
    "            import shutil\n",
    "            \n",
    "            zip_path = f\"/content/{session_dir.name}.zip\"\n",
    "            shutil.make_archive(zip_path.replace('.zip', ''), 'zip', session_dir)\n",
    "            \n",
    "            print(f\"\\n‚¨áÔ∏è Downloading {session_dir.name}.zip...\")\n",
    "            files.download(zip_path)\n",
    "        else:\n",
    "            print(f\"\\nüìÅ Files are in: {session_dir}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}