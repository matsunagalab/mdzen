{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/matsunagalab/mdzen/blob/main/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDZen: AI-Powered Molecular Dynamics Agent\n",
    "\n",
    "**Interactive AI assistant for setting up MD simulations with Gradio interface**\n",
    "\n",
    "This notebook provides a tabbed chat interface to interact with the MDZen AI agent:\n",
    "\n",
    "## Workflow\n",
    "\n",
    "**Phase 1: Setup** - Describe your simulation, the agent will:\n",
    "- Analyze your request and ask clarifying questions\n",
    "- Fetch structures from PDB/AlphaFold\n",
    "- Generate a structured `SimulationBrief`\n",
    "\n",
    "**Phase 2: Execute** - Step-by-step workflow execution:\n",
    "1. `prepare_complex` - Prepare protein + parameterize ligands (GAFF2/AM1-BCC)\n",
    "2. `solvate` - Add water box + ions\n",
    "3. `build_topology` - Generate Amber topology (tleap)\n",
    "4. `run_simulation` - Execute MD with OpenMM (NPT ensemble)\n",
    "\n",
    "**Visualization** - Interactive 3D trajectory viewer with py3Dmol\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. **Set API key** in Colab secrets (ANTHROPIC_API_KEY, OPENAI_API_KEY, or GOOGLE_API_KEY)\n",
    "2. **Run Setup cell** - installs Konda + dependencies (~5-10 min)\n",
    "3. **Start chatting!** - use the Gradio interface\n",
    "\n",
    "**Example prompts:**\n",
    "- \"Setup MD for PDB 1AKE in water, 1 ns at 300K\"\n",
    "- \"I want to simulate lysozyme (PDB 1LYZ) with explicit solvent\"\n",
    "- \"Run a short simulation of insulin (PDB 4INS), chain A only\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup: Install Konda and Dependencies\n",
    "\n",
    "**Konda** is a simple wrapper for conda/mamba in Google Colab.\n",
    "- No kernel restart needed (unlike condacolab)\n",
    "- Uses mamba for fast package installation\n",
    "- Installation takes ~5-10 minutes\n",
    "\n",
    "**API Key**: Set one of the following in Colab secrets:\n",
    "- `ANTHROPIC_API_KEY` for Claude\n",
    "- `OPENAI_API_KEY` for GPT-4\n",
    "- `GOOGLE_API_KEY` for Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# ============================================================================\n",
    "# Detect and set API keys from Colab secrets\n",
    "# ============================================================================\n",
    "detected_provider = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    \n",
    "    # Try to detect API keys from Colab secrets\n",
    "    api_keys = {\n",
    "        'ANTHROPIC_API_KEY': 'anthropic',\n",
    "        'OPENAI_API_KEY': 'openai',\n",
    "        'GOOGLE_API_KEY': 'google',\n",
    "    }\n",
    "    \n",
    "    for key_name, provider in api_keys.items():\n",
    "        try:\n",
    "            key_value = userdata.get(key_name)\n",
    "            if key_value:\n",
    "                os.environ[key_name] = key_value\n",
    "                if detected_provider is None:\n",
    "                    detected_provider = provider\n",
    "                print(f\"{key_name} loaded from Colab secrets ({provider})\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if detected_provider is None:\n",
    "        print(\"WARNING: No API key found in Colab secrets!\")\n",
    "        print(\"Please add one of: ANTHROPIC_API_KEY, OPENAI_API_KEY, or GOOGLE_API_KEY\")\n",
    "        print(\"Go to: Settings (gear icon) > Secrets\")\n",
    "    else:\n",
    "        print(f\"\\nUsing {detected_provider.upper()} as LLM provider\")\n",
    "else:\n",
    "    # Local - check environment variables\n",
    "    for key_name in ['ANTHROPIC_API_KEY', 'OPENAI_API_KEY', 'GOOGLE_API_KEY']:\n",
    "        if os.environ.get(key_name):\n",
    "            detected_provider = key_name.split('_')[0].lower()\n",
    "            print(f\"{key_name} found in environment ({detected_provider})\")\n",
    "            break\n",
    "\n",
    "# ============================================================================\n",
    "# Install dependencies\n",
    "# ============================================================================\n",
    "if IN_COLAB:\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Install Konda (no kernel restart needed!)\n",
    "    print(\"\\nInstalling Konda...\")\n",
    "    !pip install -q konda\n",
    "    import konda\n",
    "    konda.install()\n",
    "\n",
    "    # Accept conda terms of service\n",
    "    print(\"\\nAccepting conda terms of service...\")\n",
    "    !conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main 2>/dev/null || true\n",
    "    !conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r 2>/dev/null || true\n",
    "\n",
    "    # Install conda packages via mamba (faster than conda)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Installing AmberTools + scientific packages via mamba...\")\n",
    "    print(\"This takes ~5-10 minutes. Please wait.\")\n",
    "    print(\"=\"*60)\n",
    "    !konda run \"mamba install -y -c conda-forge ambertools=23 openmm rdkit pdbfixer\" 2>&1 | tail -20\n",
    "    print(f\"\\nConda packages installed ({time.time() - start_time:.0f}s)\")\n",
    "\n",
    "    # Clone repository\n",
    "    print(\"\\nCloning mdzen repository...\")\n",
    "    !rm -rf /content/mdzen\n",
    "    !git clone -q https://github.com/matsunagalab/mdzen.git /content/mdzen\n",
    "    %cd /content/mdzen\n",
    "\n",
    "    # Install pip dependencies\n",
    "    print(\"\\nInstalling Python dependencies...\")\n",
    "    !pip install -q gradio py3Dmol mdtraj nest_asyncio matplotlib\n",
    "    !pip install -q google-adk google-genai litellm\n",
    "    !pip install -q -e .\n",
    "\n",
    "    # Set AMBERHOME (Konda uses /root/miniforge3 by default)\n",
    "    os.environ[\"AMBERHOME\"] = \"/root/miniforge3\"\n",
    "\n",
    "    # Add paths\n",
    "    sys.path.insert(0, '/content/mdzen/src')\n",
    "    sys.path.insert(0, '/content/mdzen')\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(f\"Setup complete! ({total_time/60:.1f} minutes)\")\n",
    "    print(f\"LLM Provider: {detected_provider.upper() if detected_provider else 'NOT SET'}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nYou can now proceed to the next cell!\")\n",
    "\n",
    "else:\n",
    "    # Local development - add src to path\n",
    "    sys.path.insert(0, './src')\n",
    "    sys.path.insert(0, '.')\n",
    "    print(\"Local environment - dependencies should be pre-installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MDZen Gradio Chat Interface\n",
    "\n",
    "Interact with the AI agent to set up and execute your MD simulation!\n",
    "\n",
    "**Tabs:**\n",
    "- **Phase 1: Setup** - Describe your simulation, the agent generates a SimulationBrief\n",
    "- **Phase 2: Execute** - Run the workflow step-by-step (type 'start' then 'continue')\n",
    "- **Visualization** - View trajectory animation with py3Dmol\n",
    "\n",
    "**Example prompts:**\n",
    "- \"Setup MD for PDB 1AKE in water, 1 ns at 300K\"\n",
    "- \"I want to simulate lysozyme (PDB 1LYZ) with explicit solvent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import json\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ============================================================================\n",
    "# Global State\n",
    "# ============================================================================\n",
    "app_state = {\n",
    "    \"session_id\": None,\n",
    "    \"session_service\": None,\n",
    "    \"session_dir\": None,\n",
    "    \"simulation_brief\": None,\n",
    "    \"current_step_index\": 0,\n",
    "    \"workflow_outputs\": {},\n",
    "    \"clarification_agent\": None,\n",
    "    \"clarification_toolsets\": None,\n",
    "    \"setup_agent\": None,\n",
    "    \"setup_toolsets\": None,\n",
    "}\n",
    "\n",
    "# Workflow steps\n",
    "SETUP_STEPS = [\"prepare_complex\", \"solvate\", \"build_topology\", \"run_simulation\"]\n",
    "\n",
    "# ============================================================================\n",
    "# Session Initialization\n",
    "# ============================================================================\n",
    "async def init_session():\n",
    "    \"\"\"Create new session for MD workflow\"\"\"\n",
    "    import sys\n",
    "    IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "    # Generate job ID\n",
    "    import random\n",
    "    import string\n",
    "    job_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "\n",
    "    # Create session directory\n",
    "    if IN_COLAB:\n",
    "        base_dir = Path(\"/content/mdzen/outputs\")\n",
    "    else:\n",
    "        base_dir = Path(\"./outputs\")\n",
    "\n",
    "    session_dir = base_dir / f\"job_{job_id}\"\n",
    "    session_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    app_state[\"session_id\"] = f\"job_{job_id}\"\n",
    "    app_state[\"session_dir\"] = str(session_dir)\n",
    "\n",
    "    return session_dir\n",
    "\n",
    "# ============================================================================\n",
    "# Phase 1: Clarification Chat\n",
    "# ============================================================================\n",
    "def phase1_chat(message, history):\n",
    "    \"\"\"Phase 1: Gather requirements and generate SimulationBrief\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "\n",
    "        # Initialize session if needed\n",
    "        if app_state[\"session_dir\"] is None:\n",
    "            loop.run_until_complete(init_session())\n",
    "\n",
    "        # Lazy import agents\n",
    "        from mdzen.agents.clarification_agent import create_clarification_agent\n",
    "        from google.adk.runners import Runner\n",
    "        from google.genai import types\n",
    "        from mdzen.state.session_manager import (\n",
    "            create_session_service,\n",
    "            initialize_session_state,\n",
    "            get_session_state,\n",
    "        )\n",
    "\n",
    "        # Create session service if not exists\n",
    "        if app_state[\"session_service\"] is None:\n",
    "            db_path = Path(app_state[\"session_dir\"]) / \"session.db\"\n",
    "            app_state[\"session_service\"] = create_session_service(str(db_path), in_memory=False)\n",
    "\n",
    "            # Initialize session state\n",
    "            loop.run_until_complete(initialize_session_state(\n",
    "                session_service=app_state[\"session_service\"],\n",
    "                app_name=\"mdzen\",\n",
    "                user_id=\"default\",\n",
    "                session_id=app_state[\"session_id\"],\n",
    "                session_dir=app_state[\"session_dir\"],\n",
    "            ))\n",
    "\n",
    "        # Create clarification agent if not exists\n",
    "        if app_state[\"clarification_agent\"] is None:\n",
    "            agent, toolsets = create_clarification_agent()\n",
    "            app_state[\"clarification_agent\"] = agent\n",
    "            app_state[\"clarification_toolsets\"] = toolsets\n",
    "\n",
    "        # Run agent\n",
    "        runner = Runner(\n",
    "            app_name=\"mdzen\",\n",
    "            agent=app_state[\"clarification_agent\"],\n",
    "            session_service=app_state[\"session_service\"],\n",
    "        )\n",
    "\n",
    "        user_message = types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part(text=message)],\n",
    "        )\n",
    "\n",
    "        response_text = \"\"\n",
    "\n",
    "        async def run_agent():\n",
    "            nonlocal response_text\n",
    "            async for event in runner.run_async(\n",
    "                user_id=\"default\",\n",
    "                session_id=app_state[\"session_id\"],\n",
    "                new_message=user_message,\n",
    "            ):\n",
    "                if event.is_final_response() and event.content:\n",
    "                    # Extract text from content\n",
    "                    if hasattr(event.content, 'parts'):\n",
    "                        for part in event.content.parts:\n",
    "                            if hasattr(part, 'text'):\n",
    "                                response_text += part.text\n",
    "                    else:\n",
    "                        response_text = str(event.content)\n",
    "\n",
    "        loop.run_until_complete(run_agent())\n",
    "\n",
    "        # Check for SimulationBrief in state\n",
    "        state = loop.run_until_complete(get_session_state(\n",
    "            app_state[\"session_service\"],\n",
    "            \"mdzen\",\n",
    "            \"default\",\n",
    "            app_state[\"session_id\"]\n",
    "        ))\n",
    "\n",
    "        if state and state.get(\"simulation_brief\"):\n",
    "            app_state[\"simulation_brief\"] = state[\"simulation_brief\"]\n",
    "            # Append brief info to response\n",
    "            brief = app_state[\"simulation_brief\"]\n",
    "            if isinstance(brief, dict):\n",
    "                pdb_id = brief.get('pdb_id', 'N/A')\n",
    "                temp = brief.get('temperature', 300)\n",
    "                sim_time = brief.get('simulation_time_ns', 1.0)\n",
    "                response_text += f\"\\n\\n---\\n**SimulationBrief Generated!**\\n- PDB: {pdb_id}\\n- Temperature: {temp}K\\n- Simulation Time: {sim_time}ns\\n\\nGo to **Phase 2: Execute** tab and type 'start' to begin workflow.\"\n",
    "\n",
    "        yield response_text if response_text else \"Processing...\"\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"Error: {e}\\n\\n{traceback.format_exc()}\"\n",
    "\n",
    "# ============================================================================\n",
    "# Phase 2: Step-by-step Workflow Execution\n",
    "# ============================================================================\n",
    "def phase2_chat(message, history):\n",
    "    \"\"\"Phase 2: Execute workflow steps with user confirmation\"\"\"\n",
    "    try:\n",
    "        # Check if SimulationBrief exists\n",
    "        if not app_state[\"simulation_brief\"]:\n",
    "            yield \"Please complete Phase 1 first to generate SimulationBrief.\\n\\nGo to the **Phase 1: Setup** tab and describe your simulation.\"\n",
    "            return\n",
    "\n",
    "        msg_lower = message.lower().strip()\n",
    "\n",
    "        # Handle 'status' command\n",
    "        if msg_lower == 'status':\n",
    "            current = app_state[\"current_step_index\"]\n",
    "            if current >= len(SETUP_STEPS):\n",
    "                yield \"Workflow complete! Check the **Visualization** tab.\"\n",
    "            else:\n",
    "                completed = SETUP_STEPS[:current]\n",
    "                remaining = SETUP_STEPS[current:]\n",
    "                status = f\"**Workflow Status**\\n\\n\"\n",
    "                status += f\"Completed: {completed if completed else 'None'}\\n\"\n",
    "                status += f\"Current: {SETUP_STEPS[current]} [{current+1}/{len(SETUP_STEPS)}]\\n\"\n",
    "                status += f\"Remaining: {remaining[1:] if len(remaining) > 1 else 'None'}\\n\"\n",
    "                status += f\"\\nType 'continue' to proceed with {SETUP_STEPS[current]}.\"\n",
    "                yield status\n",
    "            return\n",
    "\n",
    "        # Handle 'start' or 'continue'\n",
    "        if msg_lower not in ['start', 'continue', 'next', 'run']:\n",
    "            yield f\"Commands:\\n- 'start' or 'continue': Execute next step\\n- 'status': Show workflow status\\n\\nCurrent step: {SETUP_STEPS[app_state['current_step_index']]} [{app_state['current_step_index']+1}/{len(SETUP_STEPS)}]\"\n",
    "            return\n",
    "\n",
    "        current_step = app_state[\"current_step_index\"]\n",
    "\n",
    "        if current_step >= len(SETUP_STEPS):\n",
    "            yield \"Workflow complete! Check the **Visualization** tab.\"\n",
    "            return\n",
    "\n",
    "        step_name = SETUP_STEPS[current_step]\n",
    "        yield f\"Starting step [{current_step+1}/{len(SETUP_STEPS)}]: **{step_name}**...\\n\"\n",
    "\n",
    "        # Execute the step\n",
    "        brief = app_state[\"simulation_brief\"]\n",
    "        session_dir = Path(app_state[\"session_dir\"])\n",
    "\n",
    "        loop = asyncio.get_event_loop()\n",
    "\n",
    "        if step_name == \"prepare_complex\":\n",
    "            result = loop.run_until_complete(execute_prepare_complex(brief, session_dir))\n",
    "        elif step_name == \"solvate\":\n",
    "            result = loop.run_until_complete(execute_solvate(brief, session_dir))\n",
    "        elif step_name == \"build_topology\":\n",
    "            result = loop.run_until_complete(execute_build_topology(brief, session_dir))\n",
    "        elif step_name == \"run_simulation\":\n",
    "            result = loop.run_until_complete(execute_run_simulation(brief, session_dir))\n",
    "        else:\n",
    "            result = f\"Unknown step: {step_name}\"\n",
    "\n",
    "        app_state[\"current_step_index\"] += 1\n",
    "\n",
    "        # Build response\n",
    "        response = f\"**Step {step_name} complete!**\\n\\n{result}\\n\\n\"\n",
    "\n",
    "        if app_state[\"current_step_index\"] >= len(SETUP_STEPS):\n",
    "            response += \"---\\n**Workflow complete!** Check the **Visualization** tab.\"\n",
    "        else:\n",
    "            next_step = SETUP_STEPS[app_state[\"current_step_index\"]]\n",
    "            response += f\"---\\nNext step: **{next_step}** [{app_state['current_step_index']+1}/{len(SETUP_STEPS)}]\\nType 'continue' to proceed.\"\n",
    "\n",
    "        yield response\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"Error in step: {e}\\n\\n{traceback.format_exc()}\"\n",
    "\n",
    "# ============================================================================\n",
    "# Workflow Step Implementations\n",
    "# ============================================================================\n",
    "async def execute_prepare_complex(brief, session_dir):\n",
    "    \"\"\"Step 1: Fetch and prepare structure\"\"\"\n",
    "    import importlib\n",
    "    import servers.structure_server as structure_module\n",
    "    importlib.reload(structure_module)\n",
    "\n",
    "    pdb_id = brief.get('pdb_id')\n",
    "    if not pdb_id:\n",
    "        return \"Error: No PDB ID specified in SimulationBrief\"\n",
    "\n",
    "    # Fetch structure\n",
    "    fetch_result = await structure_module.fetch_molecules(\n",
    "        pdb_id=pdb_id,\n",
    "        source=\"pdb\",\n",
    "        prefer_format=\"pdb\",\n",
    "        output_dir=str(session_dir)\n",
    "    )\n",
    "\n",
    "    if not fetch_result[\"success\"]:\n",
    "        return f\"Fetch failed: {fetch_result.get('errors')}\"\n",
    "\n",
    "    structure_file = fetch_result[\"file_path\"]\n",
    "\n",
    "    # Prepare complex\n",
    "    complex_result = structure_module.prepare_complex(\n",
    "        structure_file=structure_file,\n",
    "        select_chains=brief.get('select_chains'),\n",
    "        ph=brief.get('ph', 7.4),\n",
    "        process_proteins=True,\n",
    "        process_ligands=True,\n",
    "        run_parameterization=True,\n",
    "        output_dir=str(session_dir)\n",
    "    )\n",
    "\n",
    "    if not complex_result[\"success\"]:\n",
    "        return f\"Prepare failed: {complex_result.get('errors')}\"\n",
    "\n",
    "    app_state[\"workflow_outputs\"][\"structure_file\"] = structure_file\n",
    "    app_state[\"workflow_outputs\"][\"merged_pdb\"] = complex_result[\"merged_pdb\"]\n",
    "    app_state[\"workflow_outputs\"][\"complex_result\"] = complex_result\n",
    "\n",
    "    return f\"Fetched: {Path(structure_file).name}\\nPrepared: {len(complex_result['proteins'])} protein(s), {len(complex_result['ligands'])} ligand(s)\\nOutput: {Path(complex_result['merged_pdb']).name}\"\n",
    "\n",
    "async def execute_solvate(brief, session_dir):\n",
    "    \"\"\"Step 2: Solvate structure\"\"\"\n",
    "    import importlib\n",
    "    import servers.solvation_server as solvation_module\n",
    "    importlib.reload(solvation_module)\n",
    "\n",
    "    merged_pdb = app_state[\"workflow_outputs\"].get(\"merged_pdb\")\n",
    "    if not merged_pdb:\n",
    "        return \"Error: No merged_pdb from prepare_complex step\"\n",
    "\n",
    "    solvate_result = solvation_module.solvate_structure(\n",
    "        pdb_file=str(Path(merged_pdb).resolve()),\n",
    "        output_dir=str(session_dir),\n",
    "        output_name=\"solvated\",\n",
    "        dist=brief.get('box_padding', 12.0),\n",
    "        cubic=brief.get('cubic_box', True),\n",
    "        salt=True,\n",
    "        saltcon=brief.get('salt_concentration', 0.15)\n",
    "    )\n",
    "\n",
    "    if not solvate_result[\"success\"]:\n",
    "        return f\"Solvate failed: {solvate_result.get('errors')}\"\n",
    "\n",
    "    app_state[\"workflow_outputs\"][\"solvated_pdb\"] = solvate_result[\"output_file\"]\n",
    "    app_state[\"workflow_outputs\"][\"box_dimensions\"] = solvate_result.get(\"box_dimensions\")\n",
    "\n",
    "    stats = solvate_result.get('statistics', {})\n",
    "    return f\"Solvated: {stats.get('total_atoms', '?')} atoms\\nWater molecules: {stats.get('water_molecules', '?')}\\nOutput: {Path(solvate_result['output_file']).name}\"\n",
    "\n",
    "async def execute_build_topology(brief, session_dir):\n",
    "    \"\"\"Step 3: Build Amber topology\"\"\"\n",
    "    import importlib\n",
    "    import servers.amber_server as amber_module\n",
    "    importlib.reload(amber_module)\n",
    "\n",
    "    solvated_pdb = app_state[\"workflow_outputs\"].get(\"solvated_pdb\")\n",
    "    if not solvated_pdb:\n",
    "        return \"Error: No solvated_pdb from solvate step\"\n",
    "\n",
    "    # Get ligand parameters if any\n",
    "    ligand_params = []\n",
    "    complex_result = app_state[\"workflow_outputs\"].get(\"complex_result\", {})\n",
    "    for lig in complex_result.get(\"ligands\", []):\n",
    "        if lig.get(\"success\") and lig.get(\"mol2_file\"):\n",
    "            ligand_params.append({\n",
    "                \"mol2\": lig[\"mol2_file\"],\n",
    "                \"frcmod\": lig[\"frcmod_file\"],\n",
    "                \"residue_name\": lig[\"ligand_id\"][:3].upper()\n",
    "            })\n",
    "\n",
    "    amber_result = amber_module.build_amber_system(\n",
    "        pdb_file=solvated_pdb,\n",
    "        ligand_params=ligand_params if ligand_params else None,\n",
    "        box_dimensions=app_state[\"workflow_outputs\"].get(\"box_dimensions\"),\n",
    "        water_model=brief.get('water_model', 'tip3p'),\n",
    "        output_name=\"system\",\n",
    "        output_dir=str(session_dir)\n",
    "    )\n",
    "\n",
    "    if not amber_result['success']:\n",
    "        return f\"Amber build failed: {amber_result.get('errors')}\"\n",
    "\n",
    "    app_state[\"workflow_outputs\"][\"parm7\"] = amber_result['parm7']\n",
    "    app_state[\"workflow_outputs\"][\"rst7\"] = amber_result['rst7']\n",
    "\n",
    "    return f\"Topology: {Path(amber_result['parm7']).name}\\nCoordinates: {Path(amber_result['rst7']).name}\"\n",
    "\n",
    "async def execute_run_simulation(brief, session_dir):\n",
    "    \"\"\"Step 4: Run MD simulation with OpenMM\"\"\"\n",
    "    import openmm as mm\n",
    "    from openmm import app, unit\n",
    "    from openmm.app import AmberPrmtopFile, AmberInpcrdFile, Simulation, DCDReporter, PDBFile\n",
    "\n",
    "    parm7_file = app_state[\"workflow_outputs\"].get(\"parm7\")\n",
    "    rst7_file = app_state[\"workflow_outputs\"].get(\"rst7\")\n",
    "\n",
    "    if not parm7_file or not rst7_file:\n",
    "        return \"Error: No topology files from build_topology step\"\n",
    "\n",
    "    # Select platform\n",
    "    platform = None\n",
    "    platform_name = \"CPU\"\n",
    "    for name in ['CUDA', 'OpenCL', 'CPU']:\n",
    "        try:\n",
    "            platform = mm.Platform.getPlatformByName(name)\n",
    "            platform_name = name\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if platform is None:\n",
    "        return \"Error: No OpenMM platform available\"\n",
    "\n",
    "    # Load topology\n",
    "    prmtop = AmberPrmtopFile(parm7_file)\n",
    "    inpcrd = AmberInpcrdFile(rst7_file)\n",
    "\n",
    "    # Simulation parameters\n",
    "    temperature = brief.get('temperature', 300.0) * unit.kelvin\n",
    "    pressure = (brief.get('pressure_bar') or 1.0) * unit.atmosphere\n",
    "    timestep = 2.0 * unit.femtoseconds\n",
    "    sim_time = brief.get('simulation_time_ns', 0.1)\n",
    "\n",
    "    # Create system\n",
    "    system = prmtop.createSystem(\n",
    "        nonbondedMethod=app.PME,\n",
    "        nonbondedCutoff=10 * unit.angstrom,\n",
    "        constraints=app.HBonds,\n",
    "        rigidWater=True\n",
    "    )\n",
    "    system.addForce(mm.MonteCarloBarostat(pressure, temperature, 25))\n",
    "\n",
    "    # Create simulation\n",
    "    integrator = mm.LangevinMiddleIntegrator(temperature, 1/unit.picosecond, timestep)\n",
    "    simulation = Simulation(prmtop.topology, system, integrator, platform)\n",
    "    simulation.context.setPositions(inpcrd.positions)\n",
    "    if inpcrd.boxVectors:\n",
    "        simulation.context.setPeriodicBoxVectors(*inpcrd.boxVectors)\n",
    "\n",
    "    # Minimize and equilibrate\n",
    "    simulation.minimizeEnergy(maxIterations=500)\n",
    "    simulation.context.setVelocitiesToTemperature(temperature)\n",
    "\n",
    "    # Setup output\n",
    "    md_dir = session_dir / \"md_simulation\"\n",
    "    md_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    dcd_file = md_dir / \"trajectory.dcd\"\n",
    "    total_steps = int(sim_time * 1e6 / 2)  # 2 fs timestep\n",
    "    report_interval = max(100, total_steps // 100)\n",
    "    simulation.reporters.append(DCDReporter(str(dcd_file), report_interval))\n",
    "\n",
    "    # Run simulation\n",
    "    simulation.step(total_steps)\n",
    "\n",
    "    # Save final state\n",
    "    final_pdb = md_dir / \"final_state.pdb\"\n",
    "    state = simulation.context.getState(getPositions=True)\n",
    "    with open(final_pdb, 'w') as f:\n",
    "        PDBFile.writeFile(simulation.topology, state.getPositions(), f)\n",
    "\n",
    "    # Store outputs\n",
    "    app_state[\"workflow_outputs\"][\"trajectory\"] = str(dcd_file)\n",
    "    app_state[\"workflow_outputs\"][\"final_pdb\"] = str(final_pdb)\n",
    "    app_state[\"workflow_outputs\"][\"output_dir\"] = str(md_dir)\n",
    "\n",
    "    return f\"Platform: {platform_name}\\nSimulation time: {sim_time} ns\\nTrajectory: {dcd_file.name}\\nFinal structure: {final_pdb.name}\"\n",
    "\n",
    "# ============================================================================\n",
    "# Visualization Function\n",
    "# ============================================================================\n",
    "def visualize_trajectory():\n",
    "    \"\"\"Create py3Dmol visualization\"\"\"\n",
    "    try:\n",
    "        import py3Dmol\n",
    "        import mdtraj as md\n",
    "        import numpy as np\n",
    "        import tempfile\n",
    "\n",
    "        if not app_state[\"workflow_outputs\"] or 'trajectory' not in app_state[\"workflow_outputs\"]:\n",
    "            return \"<p style='color: orange;'>No trajectory available. Complete the workflow first.</p>\"\n",
    "\n",
    "        traj_file = app_state[\"workflow_outputs\"]['trajectory']\n",
    "        top_file = app_state[\"workflow_outputs\"]['parm7']\n",
    "\n",
    "        # Load trajectory\n",
    "        traj = md.load(traj_file, top=top_file)\n",
    "\n",
    "        # Select protein only\n",
    "        protein_indices = traj.topology.select('protein')\n",
    "        if len(protein_indices) == 0:\n",
    "            return \"<p>No protein atoms found in trajectory</p>\"\n",
    "\n",
    "        traj_protein = traj.atom_slice(protein_indices)\n",
    "\n",
    "        # Sample frames\n",
    "        max_frames = 20\n",
    "        if traj_protein.n_frames > max_frames:\n",
    "            frame_indices = np.linspace(0, traj_protein.n_frames - 1, max_frames, dtype=int)\n",
    "            traj_viz = traj_protein[frame_indices]\n",
    "        else:\n",
    "            traj_viz = traj_protein\n",
    "\n",
    "        # Write multi-model PDB\n",
    "        with tempfile.NamedTemporaryFile(suffix='.pdb', delete=False, mode='w') as tmp:\n",
    "            tmp_path = tmp.name\n",
    "\n",
    "        with open(tmp_path, 'w') as f:\n",
    "            for i in range(traj_viz.n_frames):\n",
    "                frame_tmp = tmp_path + f\".frame{i}.pdb\"\n",
    "                traj_viz[i].save_pdb(frame_tmp, force_overwrite=True)\n",
    "                with open(frame_tmp, 'r') as ff:\n",
    "                    content = ff.read()\n",
    "                f.write(f\"MODEL     {i + 1}\\n\")\n",
    "                for line in content.split('\\n'):\n",
    "                    if not line.startswith('MODEL') and not line.startswith('ENDMDL') and line.strip():\n",
    "                        f.write(line + '\\n')\n",
    "                f.write(\"ENDMDL\\n\")\n",
    "                Path(frame_tmp).unlink()\n",
    "\n",
    "        with open(tmp_path, 'r') as f:\n",
    "            traj_pdb = f.read()\n",
    "        Path(tmp_path).unlink()\n",
    "\n",
    "        # Create 3D view\n",
    "        view = py3Dmol.view(width=800, height=500)\n",
    "        view.addModelsAsFrames(traj_pdb, 'pdb')\n",
    "        view.setStyle({'cartoon': {'color': 'spectrum'}})\n",
    "        view.zoomTo()\n",
    "        view.animate({'loop': 'forward', 'reps': 0, 'interval': 100})\n",
    "\n",
    "        # Get HTML\n",
    "        html = view._make_html()\n",
    "\n",
    "        info = f\"<p><b>Trajectory Animation:</b> {traj_viz.n_frames} frames | Total time: {traj.time[-1]:.1f} ps</p>\"\n",
    "        return info + html\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"<p style='color: red;'>Error: {e}</p>\"\n",
    "\n",
    "# ============================================================================\n",
    "# Build Gradio Interface\n",
    "# ============================================================================\n",
    "with gr.Blocks(title=\"MDZen: AI-Powered MD Agent\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# MDZen: AI-Powered Molecular Dynamics Agent\")\n",
    "\n",
    "    with gr.Tabs():\n",
    "        with gr.Tab(\"Phase 1: Setup\"):\n",
    "            gr.Markdown(\"\"\"Describe your simulation and I'll help you configure it.\n",
    "\n",
    "            When the SimulationBrief is generated, go to **Phase 2: Execute** tab.\"\"\")\n",
    "            gr.ChatInterface(\n",
    "                fn=phase1_chat,\n",
    "                examples=[\n",
    "                    \"Setup MD for PDB 1AKE in water, 1 ns at 300K\",\n",
    "                    \"Simulate lysozyme (PDB 1LYZ) with explicit solvent\",\n",
    "                    \"Run a short simulation of insulin (PDB 4INS), chain A only\",\n",
    "                ],\n",
    "                retry_btn=None,\n",
    "                undo_btn=None,\n",
    "            )\n",
    "\n",
    "        with gr.Tab(\"Phase 2: Execute\"):\n",
    "            gr.Markdown(\"\"\"Execute the MD workflow step by step:\n",
    "\n",
    "            1. **prepare_complex** - Fetch structure and parameterize ligands\n",
    "            2. **solvate** - Add water box and ions\n",
    "            3. **build_topology** - Generate Amber topology files\n",
    "            4. **run_simulation** - Run MD with OpenMM\n",
    "\n",
    "            **Commands:** 'start', 'continue', 'status'\"\"\")\n",
    "            gr.ChatInterface(\n",
    "                fn=phase2_chat,\n",
    "                examples=[\"start\", \"continue\", \"status\"],\n",
    "                retry_btn=None,\n",
    "                undo_btn=None,\n",
    "            )\n",
    "\n",
    "        with gr.Tab(\"Visualization\"):\n",
    "            gr.Markdown(\"3D visualization of your simulation results\")\n",
    "            viz_btn = gr.Button(\"Load Trajectory\", variant=\"primary\")\n",
    "            viz_output = gr.HTML()\n",
    "            viz_btn.click(visualize_trajectory, outputs=viz_output)\n",
    "\n",
    "# Launch\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if app_state[\"session_dir\"]:\n",
    "    session_dir = Path(app_state[\"session_dir\"])\n",
    "\n",
    "    if session_dir.exists():\n",
    "        print(f\"Session directory: {session_dir}\")\n",
    "        print(\"\\nGenerated files:\")\n",
    "        for f in sorted(session_dir.rglob('*')):\n",
    "            if f.is_file():\n",
    "                rel_path = f.relative_to(session_dir)\n",
    "                size_kb = f.stat().st_size / 1024\n",
    "                print(f\"  {rel_path} ({size_kb:.1f} KB)\")\n",
    "\n",
    "        if IN_COLAB:\n",
    "            from google.colab import files\n",
    "            import shutil\n",
    "\n",
    "            zip_name = f\"{session_dir.name}.zip\"\n",
    "            shutil.make_archive(str(session_dir), 'zip', session_dir)\n",
    "            print(f\"\\nDownloading {zip_name}...\")\n",
    "            files.download(f\"{session_dir}.zip\")\n",
    "        else:\n",
    "            print(f\"\\nFiles are in: {session_dir}\")\n",
    "    else:\n",
    "        print(\"Session directory not found.\")\n",
    "else:\n",
    "    print(\"No session available. Run the workflow first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Longer simulations**: Modify the simulation time in your Phase 1 request\n",
    "2. **Analysis**: Use MDTraj for RMSD, RMSF, hydrogen bonds, etc.\n",
    "3. **Different systems**: Try membrane proteins, protein-ligand complexes\n",
    "4. **Command line**: Use `main.py run` for local development\n",
    "\n",
    "For more information, see the [GitHub repository](https://github.com/matsunagalab/mdzen)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
